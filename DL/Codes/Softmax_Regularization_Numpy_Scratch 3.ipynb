{"cells":[{"cell_type":"markdown","id":"HeWgOD1uD1YP","metadata":{"id":"HeWgOD1uD1YP"},"source":["---\n","\n","Load libraries\n","\n","---"]},{"cell_type":"code","execution_count":1,"id":"FXrh9fPyMtwx","metadata":{"id":"FXrh9fPyMtwx","executionInfo":{"status":"ok","timestamp":1736960967255,"user_tz":-330,"elapsed":16211,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}}},"outputs":[],"source":["## Load libraries\n","import pandas as pd\n","import numpy as np\n","import sys\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import tensorflow as tf\n","from sklearn.metrics import confusion_matrix\n","plt.style.use('dark_background')\n","%matplotlib inline"]},{"cell_type":"markdown","id":"ttFTTWbqD4eQ","metadata":{"id":"ttFTTWbqD4eQ"},"source":["---\n","\n","Set printing precision\n","\n","---"]},{"cell_type":"code","execution_count":2,"id":"P3UMZJowDzo0","metadata":{"id":"P3UMZJowDzo0","executionInfo":{"status":"ok","timestamp":1736960967256,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}}},"outputs":[],"source":["np.set_printoptions(precision = 2)"]},{"cell_type":"markdown","id":"DIsc4Twv6UhG","metadata":{"id":"DIsc4Twv6UhG"},"source":["---\n","\n","Mount Google drive\n","\n","---"]},{"cell_type":"code","execution_count":3,"id":"0s0mudRDMxGf","metadata":{"id":"0s0mudRDMxGf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736960998324,"user_tz":-330,"elapsed":31075,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}},"outputId":"5c9f203b-79e5-4bd2-df93-4323482c751d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## Mount Google drive folder if running in Colab\n","if('google.colab' in sys.modules):\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount = True)\n","    DIR = '/content/drive/MyDrive/Colab Notebooks/EvenSemester2024/DL/Codes'\n","    DATA_DIR = DIR + '/Data/'\n","else:\n","    DATA_DIR = 'Data/'"]},{"cell_type":"markdown","id":"D6DHQ6D8CCH9","metadata":{"id":"D6DHQ6D8CCH9"},"source":["---\n","\n","Load MNIST Data\n","\n","---"]},{"cell_type":"code","execution_count":4,"id":"CRfIzvOsCDFR","metadata":{"id":"CRfIzvOsCDFR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736961105211,"user_tz":-330,"elapsed":3711,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}},"outputId":"e7dcfe2b-b208-4c6e-eada-48be4d1af2a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","MNIST set\n","---------------------\n","Number of training samples = 60000\n","Number of features = 784\n","Number of output labels = 10\n"]}],"source":["## Load MNIST data\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n","\n","num_labels = len(np.unique(y_train))\n","num_features = X_train.shape[1]\n","num_samples = X_train.shape[0]\n","\n","# One-hot encode class labels\n","Y_train = tf.keras.utils.to_categorical(y_train)\n","Y_test = tf.keras.utils.to_categorical(y_test)\n","\n","# Normalize the samples (images) using the training data\n","xmax = np.amax(X_train) # 255\n","xmin = np.amin(X_train) # 0\n","X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n","X_test = (X_test - xmin) / (xmax - xmin)\n","\n","print('MNIST set')\n","print('---------------------')\n","print('Number of training samples = %d'%(num_samples))\n","print('Number of features = %d'%(num_features))\n","print('Number of output labels = %d'%(num_labels))"]},{"cell_type":"markdown","id":"BxG1YM906sEr","metadata":{"id":"BxG1YM906sEr"},"source":["---\n","\n","We consider a softmax classfier, which is a 1-layer neural network or a 0-hidden layer neural network, for a batch comprising $b$ samples represented as the $b\\times 784$-matrix $$\\mathbf{X} = \\begin{bmatrix}{\\mathbf{x}^{(0)}}^\\mathrm{T}\\\\{\\mathbf{x}^{(1)}}^\\mathrm{T}\\\\\\vdots\\\\{\\mathbf{x}^{(b-1)}}^\\mathrm{T}\\end{bmatrix}$$ with one-hot encoded true labels represented as the $b\\times 10$-matrix (10 possible categories) $$\\mathbf{Y}=\\begin{bmatrix}{\\mathbf{y}^{(0)}}^\\mathrm{T}\\\\{\\mathbf{y}^{(1)}}^\\mathrm{T}\\\\\\vdots\\\\{\\mathbf{y}^{(b-1)}}^\\mathrm{T}\\end{bmatrix}.$$\n","\n","The forward propagation for a generic sample in the batch seen as a $1\\times784$-object $\\mathbf{x}^\\mathrm{T}$ with the bias feature $1$ added is presented below:\n","\n","$$\\small\\begin{align*}\n","\\boxed{\\underbrace{\\mathbf{x}_B^\\mathrm{T}}_{1\\times785}=\\begin{bmatrix}\\mathbf{x}^\\mathrm{T}&1\\end{bmatrix}}&\\rightarrow\\boxed{\\underbrace{{\\mathbf{z}}^\\mathrm{T}}_{1\\times 10} = \\underbrace{\\mathbf{x}_B^\\mathrm{T}}_{1\\times785}\\underbrace{{\\mathbf{W}}}_{785\\times10}}\\rightarrow\\boxed{\\underbrace{{\\mathbf{a}}^\\mathrm{T}}_{1\\times10}=\\text{softmax}\\left(\\underbrace{{\\mathbf{z}}^\\mathrm{T}}_{1\\times10}\\right)}\\rightarrow\\boxed{L = \\sum\\limits_{k=0}^9-y_k\\log\\left(\\hat{y}_k\\right)}.\n","\\end{align*}$$\n","\n","The forward propagation for the same generic sample seen as a $784$-vector $\\mathbf{x}$ with the bias feature $1$ added is presented below (note that the weight matrix has the same name $\\mathbf{W}$ as above for simplicity even though it should show up as $\\mathbf{W}^\\mathrm{T}$):\n","\n","$$\\small\\begin{align*}\n","\\boxed{\\underbrace{\\mathbf{x}_B}_{785}=\\begin{bmatrix}\\mathbf{x}\\\\1\\end{bmatrix}}&\\rightarrow\\boxed{\\underbrace{\\mathbf{z}}_{10} = \\underbrace{\\mathbf{W}}_{10\\times785}\\underbrace{\\mathbf{x}_B}_{785}}\\rightarrow\\boxed{\\underbrace{\\mathbf{a}}_{10}=\\text{softmax}\\left(\\underbrace{\\mathbf{z}}_{10}\\right)}\\rightarrow\\boxed{L = \\sum\\limits_{k=0}^9-y_k\\log\\left(\\hat{y}_k\\right)}.\\end{align*}$$\n","\n","We will derive the update rule for the weights matrix $\\mathbf{W}$ using the setup above.\n","\n","\n","The average crossentropy (CCE) loss for the batch is:$$\\begin{align*}L &=\\frac{1}{b}\\left[L_0+L_1+\\cdots+L_{b-1}\\right]\\\\&=\\frac{1}{b}\\left[\\sum\\limits_{k=0}^9{\\color{yellow}-}y_k^{(0)}\\log\\left(\\hat{y}^{(0)}_k\\right)+\\sum\\limits_{k=0}^9{\\color{yellow}-}y_k^{(1)}\\log\\left(\\hat{y}^{(1)}_k\\right)+\\cdots+\\sum\\limits_{k=0}^9{\\color{yellow}-}y_k^{(b-1)}\\log\\left(\\hat{y}^{(b-1)}_k\\right)\\right]\\\\&=\\frac{1}{b}\\left[{\\color{yellow}-}{\\mathbf{y}^{(0)}}^\\mathrm{T}\\log\\left({\\hat{\\mathbf{y}}^{(0)}}\\right)+{\\color{yellow}-}{\\mathbf{y}^{(1)}}^\\mathrm{T}\\log\\left({\\hat{\\mathbf{y}}^{(1)}}\\right)+\\cdots+{\\color{yellow}-}{\\mathbf{y}^{(b-1)}}^\\mathrm{T}\\log\\left({\\hat{\\mathbf{y}}^{(b-1)}}\\right)\\right].\\end{align*}$$\n","\n","The computational graph for the samples, each at a time treated as a $785$-vector, in the batch are presented below where the weights matrix has shape $10\\times 785.$\n","\n","$\\hspace{1.5in}\\begin{align*}L_0\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(0)} &= \\mathbf{a}^{(0)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(0)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$$\\hspace{0.25in}\\begin{align*}L_1\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(1)} &= \\mathbf{a}^{(1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$$\\qquad\\cdots\\qquad$$\\begin{align*} L_{b-1}\\\\{\\color{yellow}\\downarrow}\\\\ \\hat{\\mathbf{y}}^{(b-1)} &= \\mathbf{a}^{(b-1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{z}^{(b-1)}\\\\{\\color{yellow}\\downarrow}\\\\\\mathbf{W}\\end{align*}$\n","\n","The gradient of the average batch loss w.r.t. the weights is:\n","$$\\small\\begin{align*}\\Rightarrow \\nabla_\\mathbf{W}(L) &=\\frac{1}{b}\\left[\\nabla_\\mathbf{W}(L_0)+\\nabla_\\mathbf{W}(L_1)+\\cdots+\\nabla_\\mathbf{W}(L_{b-1})\\right]\\end{align*}$$\n","which by chain rule can be written as:\n","\n","$$\\small\\begin{align*}\\Rightarrow \\nabla_\\mathbf{W}(L) &= \\frac{1}{b}\\left(\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(0)}\\right) \\times\\nabla_{\\mathbf{z}^{(0)}}\\left(\\hat{\\mathbf{y}}^{(0)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(0)}}(L_0)\\right]}_{\\nabla_\\mathbf{W}(L_0)}+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(1)}\\right) \\times\\nabla_{\\mathbf{z}^{(1)}}\\left(\\hat{\\mathbf{y}}^{(1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(1)}}(L_1)\\right]}_{\\nabla_\\mathbf{W}(L_1)}+\\cdots+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(b-1)}\\right) \\times\\nabla_{\\mathbf{z}^{(b-1)}}\\left(\\hat{\\mathbf{y}}^{(b-1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(b-1)}}(L_{b-1})\\right]}_{\\nabla_\\mathbf{W}(L_{b-1})}\\right)\\\\&=\\frac{1}{b}\\left(\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(0)}\\right) \\times\\nabla_{\\mathbf{z}^{(0)}}\\left({\\mathbf{a}}^{(0)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(0)}}(L_0)\\right]}_{\\nabla_\\mathbf{W}(L_0)}+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(1)}\\right) \\times\\nabla_{\\mathbf{z}^{(1)}}\\left({\\mathbf{a}}^{(1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(1)}}(L_1)\\right]}_{\\nabla_\\mathbf{W}(L_1)}+\\cdots+\\underbrace{\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(b-1)}\\right) \\times\\nabla_{\\mathbf{z}^{(b-1)}}\\left(\\hat{\\mathbf{y}}^{(b-1)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(b-1)}}(L_{b-1})\\right]}_{\\nabla_\\mathbf{W}(L_{b-1})}\\right)\\\\&=\\frac{1}{b}\\sum_{i=0}^{b-1}\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(i)}\\right) \\times\\nabla_{\\mathbf{z}^{(i)}}\\left({\\mathbf{a}}^{(i)}\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(i)}}(L_i)\\right]\\\\&=\\frac{1}{b}\\sum_{i=0}^{b-1}\\left[\\nabla_\\mathbf{W}\\left(\\mathbf{W}{\\mathbf{x}^{(i)}_B}\\right) \\times\\nabla_{\\mathbf{z}^{(i)}}\\left(\\text{softmax}\\left({\\mathbf{z}}^{(i)}\\right)\\right)\\times\\nabla_{\\hat{\\mathbf{y}}^{(i)}}\\left(-{\\mathbf{y}^{(i)}}^\\mathrm{T}\\log\\left(\\hat{\\mathbf{y}}^{(i)}\\right)\\right)\\right],\\end{align*}$$\n","which can be written as\n","\n","$$\\begin{align*}\\nabla_{\\mathbf{W}}(L) &= \\dfrac{1}{b}\\displaystyle\\sum_{i=0}^{b-1}\\underbrace{\\begin{bmatrix}\\boxed{{\\mathbf{x}^{(i)}_B}\\ \\pmb{0}\\ \\pmb{0}\\ \\ldots\\ \\pmb{0}}&&&&\\\\\\\\&\\boxed{\\pmb{0}\\ {\\mathbf{x}^{(i)}_B}\\ \\pmb{0}\\ \\ldots\\ \\pmb{0}}&&&\\\\&\\hspace{1cm}\\ddots&&&\\\\&&\\hspace{-0.5cm}\\ddots&&\\\\&&&\\boxed{\\pmb{0}\\ \\pmb{0}\\ \\ldots\\ \\pmb{0}\\ {\\mathbf{x}^{(i)}_B}}&\\end{bmatrix}}_{\\color{cyan}{\\nabla_\\mathbf{W}\\left(\\mathbf{z}^{(i)}\\right)=\\nabla_\\mathbf{W}\\left(\\mathbf{W}{\\mathbf{x}^{(i)}_B}\\right):\\ 10\\times785\\times10}}\\underbrace{\\begin{bmatrix}a^{(i)}_0 (1 - a^{(i)}_0) & -a^{(i)}_0 a^{(i)}_1 & \\cdots & -a^{(i)}_0 a^{(i)}_9\\\\-a^{(i)}_1 a^{(i)}_0 & a^{(i)}_1 (1 - a^{(i)}_1) & \\cdots & -a^{(i)}_1 a^{(i)}_9\\\\\\vdots & \\vdots & \\ddots & \\vdots\\\\-a^{(i)}_9 a^{(i)}_0 & -a^{(i)}_9 a^{(i)}_1 & \\cdots & a^{(i)}_9 (1 - a^{(i)}_9)\\end{bmatrix}}_{\\color{cyan}{\\nabla_{\\mathbf{z}^{(i)}}\\left({\\mathbf{a}}^{(i)}\\right) = \\nabla_{\\mathbf{z}^{(i)}}\\left(\\text{softmax}\\left({\\mathbf{z}}^{(i)}\\right)\\right):\\ 10\\times10}}\\underbrace{\\begin{bmatrix}-\\frac{y^{(i)}_0}{\\hat{y}^{(i)}_0}\\\\-\\frac{y^{(i)}_1}{\\hat{y}^{(i)}_1}\\\\\\vdots\\\\-\\frac{y^{(i)}_9}{\\hat{y}^{(i)}_9}\\end{bmatrix}}_{\\color{cyan}{\\nabla_{\\hat{\\mathbf{y}}^{(i)}}(L_i)=\\nabla_{\\hat{\\mathbf{y}}^{(i)}}\\left(-{\\mathbf{y}^{(i)}}^\\mathrm{T}\\log\\left(\\hat{\\mathbf{y}}^{(i)}\\right)\\right):\\ 10\\times1}}\\end{align*}$$\n","\n","The forward and backward propagation showing the gradient flow for a generic sample is shown below:\n","\n","![](https://1drv.ms/i/c/37720f927b6ddc34/IQS3b-biQ4W9QpCtJzaZnyCoAQ8_r9i707rpOE1O9I0yntM?width=686&height=93)\n","\n","$$\\begin{align*}\\nabla_{\\mathbf{W}}(L) &=\\dfrac{1}{b}\\displaystyle\\sum_{i=0}^{b-1}\\underbrace{\\begin{bmatrix}a^{(i)}_0 (1 - a^{(i)}_0) & -a^{(i)}_0 a^{(i)}_1 & \\cdots & -a^{(i)}_0 a^{(i)}_9\\\\-a^{(i)}_1 a^{(i)}_0 & a^{(i)}_1 (1 - a^{(i)}_1) & \\cdots & -a^{(i)}_1 a^{(i)}_9\\\\\\vdots & \\vdots & \\ddots & \\vdots\\\\-a^{(i)}_9 a^{(i)}_0 & -a^{(i)}_9 a^{(i)}_1 & \\cdots & a^{(i)}_9 (1 - a^{(i)}_9)\\end{bmatrix}}_{\\color{cyan}{=\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right)\\otimes\\mathbf{a}^{(i)}}}\\underbrace{\\begin{bmatrix}-\\frac{y^{(i)}_0}{\\hat{y}^{(i)}_0} \\\\\n","-\\frac{y^{(i)}_1}{\\hat{y}^{(i)}_1}\\\\\\vdots\\\\-\\frac{y^{(i)}_9}{\\hat{y}^{(i)}_9}\\end{bmatrix}}_{\\color{cyan}{=-\\frac{\\mathbf{y}^{(i)}}{\\hat{\\mathbf{y}}^{(i)}}}}{\\mathbf{x}^{(i)}_B}^\\mathrm{T}.\\end{align*}$$\n","\n","We can write the gradient in the following way for efficient coding purposes: $$\\nabla_\\mathbf{W}(L) = \\frac{1}{b}\\sum_{i=0}^{b-1}\\left[\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right)\\otimes\\mathbf{a}^{(i)}\\right]\\left[-\\frac{\\mathbf{y}^{(i)}}{\\hat{\\mathbf{y}}^{(i)}}\\right]{\\mathbf{x}^{(i)}_B}^\\mathrm{T}.$$\n","\n","\n","It can be seen that the gradient object has shape $(10\\times 10)\\times(10\\times1)\\times(1\\times785)=10\\times785,$ which is the same shape as the weights matrix $\\mathbf{W}.$ However, our derivation here assumed that the samples are seen as column vectors of the data matrix. The original data matrix has the samples arranged as rows which corresponded to the weights matrix of shape $785\\times10.$ In order to get the gradient w.r.t. that weights matrix, we have to transpose this expression resulting in the update $$\\nabla_\\mathbf{W}(L) = \\frac{1}{b}\\sum_{i=0}^{b-1}\\underbrace{\\mathbf{x}^{(i)}_B}_{\\color{yellow}{785\\times1}}\\underbrace{\\underbrace{\\left[-\\frac{{\\mathbf{y}^{(i)}}^\\mathrm{T}}{{\\hat{\\mathbf{y}}^{(i)}}^\\mathrm{T}}\\right]}_{\\color{magenta}{\\text{output side gradient of softmax layer: }1\\times10}}\\underbrace{\\left[\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}\\right)\\otimes{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right]}_{\\color{magenta}{\\text{local gradient of softmax layer: }10\\times10}}}_{\\color{yellow}{\\text{output side gradient of dense layer: }1\\times10}}.$$\n","\n","\n","\n","Note that when regularization is applied to the weights using a regularization strength $\\lambda,$ then the regularization loss gets added to the data loss to give the total loss for the batch as follows: $$\\begin{align*}L &= L_\\text{data}+L_\\text{reg}\\\\&=\\frac{1}{b}\\left[L_0+L_1+\\cdots+L_{b-1}\\right]+\\lambda\\left[{\\mathbf{w}^{(0)}}^\\mathrm{T}\\mathbf{w}^{(0)}+{\\mathbf{w}^{(1)}}^\\mathrm{T}\\mathbf{w}^{(1)}+\\cdots+{\\mathbf{w}^{(783)}}^\\mathrm{T}\\mathbf{w}^{(783)}\\right].\\end{align*}$$\n","Note that the last row of the weights matrix $\\mathbf{W},$ which comprises the bias values, are not included in the regularization loss.\n","\n","The gradient w.r.t. the weights matrix $\\mathbf{W}$ now also includes the gradient w.r.t. the regularization loss as follows: $$\\begin{align*}\\nabla_\\mathbf{W}(L)&=\\nabla_\\mathbf{W}\\left(\\frac{1}{b}\\left[L_0+L_1+\\cdots+L_{b-1}\\right]\\right)+\\lambda\\nabla_\\mathbf{W}\\left(L_\\text{reg}\\right)\\\\&=\\underbrace{\\frac{1}{b}\\sum_{i=0}^{b-1}{\\mathbf{x}^{(i)}_B}\\left[-\\frac{{\\mathbf{y}^{(i)}}^\\mathrm{T}}{{\\hat{\\mathbf{y}}^{(i)}}^\\mathrm{T}}\\right]\\left[\\left(\\mathbf{I}-{\\mathbf{a}^{(i)}}\\right)\\otimes{\\mathbf{a}^{(i)}}^\\mathrm{T}\\right]}_{\\text{data gradient}}+\\lambda\\underbrace{\\begin{bmatrix}2{\\mathbf{w}^{(0)}}^\\mathrm{T}\\\\2{\\mathbf{w}^{(1)}}^\\mathrm{T}\\\\\\vdots\\\\2{\\mathbf{w}^{(783)}}^\\mathrm{T}\\\\\\pmb{0}\\end{bmatrix}}_{\\text{regularization gradient}}.\\end{align*}$$\n","\n","\n","---"]},{"cell_type":"markdown","id":"oKggGU1vRBif","metadata":{"id":"oKggGU1vRBif"},"source":["---\n","\n","A generic layer class with forward and backward methods\n","\n","----"]},{"cell_type":"code","execution_count":5,"id":"tZHmwpk4Q404","metadata":{"id":"tZHmwpk4Q404","executionInfo":{"status":"ok","timestamp":1736961137404,"user_tz":-330,"elapsed":585,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}}},"outputs":[],"source":["class Layer:\n","  def __init__(self):\n","    self.input = None\n","    self.output = None\n","\n","  def forward(self, input):\n","    pass\n","\n","  def backward(self, output_gradient, learning_rate):\n","    pass"]},{"cell_type":"markdown","id":"s6nr7yGIRsa3","metadata":{"id":"s6nr7yGIRsa3"},"source":["---\n","\n","CCE loss and its gradient for the batch samples\n","\n","---"]},{"cell_type":"code","execution_count":6,"id":"ivzPpy3FRtQE","metadata":{"id":"ivzPpy3FRtQE","executionInfo":{"status":"ok","timestamp":1736961296506,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}}},"outputs":[],"source":["## Define the loss function and its gradient\n","def cce(Y, Yhat):\n","  return(np.mean(np.sum(-Y*np.log(Yhat), axis = 1), axis = 0))\n","  #TensorFlow in-built function for categorical crossentropy loss\n","  #cce = tf.keras.losses.CategoricalCrossentropy()\n","  #return(cce(Y, Yhat).numpy())\n","\n","def cce_gradient(Y, Yhat):\n","  return(-Y/Yhat)"]},{"cell_type":"markdown","id":"t_hwSUUiVlWD","metadata":{"id":"t_hwSUUiVlWD"},"source":["---\n","\n","Softmax activation layer class\n","\n","\n","---"]},{"cell_type":"code","execution_count":7,"id":"6bVplzEcMWlP","metadata":{"id":"6bVplzEcMWlP","executionInfo":{"status":"ok","timestamp":1736961297923,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}}},"outputs":[],"source":["## Softmax activation layer class\n","class Softmax(Layer):\n","  def forward(self, input):\n","    self.input = input\n","    self.output = tf.nn.softmax(self.input, axis = 1).numpy()\n","\n","  def backward(self, output_gradient, learning_rate = None):\n","    I = np.identity(self.output.shape[1])\n","    local_gradient = (I - self.output[:, :, np.newaxis]) * self.output[:, np.newaxis, :]\n","    return(np.einsum('ij,ijk->ik', output_gradient, local_gradient))"]},{"cell_type":"markdown","id":"HCDIPQkp7JmN","metadata":{"id":"HCDIPQkp7JmN"},"source":["---\n","\n","Dense layer class\n","\n","---"]},{"cell_type":"code","execution_count":8,"id":"aLs-dsgv7Nxl","metadata":{"id":"aLs-dsgv7Nxl","executionInfo":{"status":"ok","timestamp":1736961455232,"user_tz":-330,"elapsed":821,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}}},"outputs":[],"source":["## Dense layer class\n","class Dense(Layer):\n","    def __init__(self, input_size, output_size, reg_strength = 0.0):\n","        self.weights = 0.01*np.random.randn(input_size+1, output_size) # bias trick\n","        self.weights[-1, :] = 0.01 # set all bias values to the same nonzero constant\n","        self.reg_strength = reg_strength\n","        self.reg_loss = None\n","\n","    def forward(self, input):\n","        self.input = np.hstack([input, np.ones((input.shape[0], 1))]) # bias trick\n","        # Forward propagation\n","        self.output= np.dot(self.input, self.weights)\n","        # Calculate regularization loss\n","        self.reg_loss = self.reg_strength * np.sum(self.weights[:-1, :] * self.weights[:-1, :])\n","\n","    def backward(self, output_gradient, learning_rate):\n","        # Calculate gradient w.r.t. dense layer weights from all inputs\n","        weights_gradient = (1/output_gradient.shape[0]) * (np.einsum('ij,ik->jk', self.input, output_gradient))\n","        # Add the regularization gradient here\n","        weights_gradient += 2 * self.reg_strength * np.vstack([self.weights[:-1, :], np.zeros((1, self.weights.shape[1]))])\n","        # Update weights for dense layer\n","        self.weights = self.weights + learning_rate * (-weights_gradient)"]},{"cell_type":"markdown","id":"Pr2pX28071bj","metadata":{"id":"Pr2pX28071bj"},"source":["---\n","\n","Function to generate sample indices for batch processing according to batch size\n","\n","---"]},{"cell_type":"code","execution_count":9,"id":"z7TmsRrw72LB","metadata":{"id":"z7TmsRrw72LB","executionInfo":{"status":"ok","timestamp":1736961475921,"user_tz":-330,"elapsed":735,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}}},"outputs":[],"source":["## Function to generate sample indices for batch processing according to batch size\n","def generate_batch_indices(num_samples, batch_size):\n","  # Reorder sample indices\n","  reordered_sample_indices = np.random.choice(num_samples, num_samples, replace = False)\n","  # Generate batch indices for batch processing\n","  batch_indices = np.split(reordered_sample_indices, np.arange(batch_size, len(reordered_sample_indices), batch_size))\n","  return(batch_indices)"]},{"cell_type":"markdown","id":"XNNMRK7u75l7","metadata":{"id":"XNNMRK7u75l7"},"source":["---\n","\n","Example generation of batch indices\n","\n","---"]},{"cell_type":"code","execution_count":10,"id":"Q34Ulk_v78bv","metadata":{"id":"Q34Ulk_v78bv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736961477442,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}},"outputId":"22e070ab-79ed-4ec2-e326-12c308e55e54"},"outputs":[{"output_type":"stream","name":"stdout","text":["[array([13, 45,  8, 14,  6, 55, 50,  9, 32, 59,  0, 16, 34, 36, 49, 26]), array([41, 19, 63, 17, 20, 40,  1, 35, 42, 23, 24, 43, 46, 61, 12, 31]), array([54, 57, 28, 60, 18, 10, 33, 44, 53,  7, 15, 47, 56, 58,  4, 38]), array([62, 37, 51, 27, 48, 52,  3, 22,  2,  5, 11, 29, 25, 39, 21, 30])]\n"]}],"source":["## Example generation of batch indices\n","batch_size = 16\n","batch_indices = generate_batch_indices(64, batch_size)\n","print(batch_indices)"]},{"cell_type":"markdown","id":"BzW-2lIo8As4","metadata":{"id":"BzW-2lIo8As4"},"source":["---\n","\n","Train the 1-layer neural (softmax) neural network using batch training with batch size = 100\n","\n","---"]},{"cell_type":"code","execution_count":31,"id":"Jzk8_9Xl8Bdu","metadata":{"id":"Jzk8_9Xl8Bdu","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1736965560309,"user_tz":-330,"elapsed":102339,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}},"outputId":"1e4fafbb-27a8-4320-d959-0a477d0123b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: train loss = 1.530762, test loss = 1.334671\n","Epoch 2: train loss = 1.349964, test loss = 1.321524\n","Epoch 3: train loss = 1.344343, test loss = 1.319655\n","Epoch 4: train loss = 1.342193, test loss = 1.317368\n","Epoch 5: train loss = 1.340616, test loss = 1.315725\n","Epoch 6: train loss = 1.339018, test loss = 1.314134\n","Epoch 7: train loss = 1.337686, test loss = 1.313425\n","Epoch 8: train loss = 1.336498, test loss = 1.312158\n","Epoch 9: train loss = 1.335619, test loss = 1.311157\n","Epoch 10: train loss = 1.334676, test loss = 1.310651\n","Epoch 11: train loss = 1.333817, test loss = 1.309821\n","Epoch 12: train loss = 1.333158, test loss = 1.308919\n","Epoch 13: train loss = 1.332288, test loss = 1.309182\n","Epoch 14: train loss = 1.331871, test loss = 1.308543\n","Epoch 15: train loss = 1.331382, test loss = 1.307835\n","Epoch 16: train loss = 1.331006, test loss = 1.306936\n","Epoch 17: train loss = 1.330582, test loss = 1.307016\n","Epoch 18: train loss = 1.330141, test loss = 1.306531\n","Epoch 19: train loss = 1.329884, test loss = 1.306246\n","Epoch 20: train loss = 1.329624, test loss = 1.305854\n","Epoch 21: train loss = 1.329332, test loss = 1.305984\n","Epoch 22: train loss = 1.329193, test loss = 1.305308\n","Epoch 23: train loss = 1.328998, test loss = 1.305152\n","Epoch 24: train loss = 1.328821, test loss = 1.305102\n","Epoch 25: train loss = 1.328613, test loss = 1.304636\n","Epoch 26: train loss = 1.328477, test loss = 1.304906\n","Epoch 27: train loss = 1.328376, test loss = 1.304440\n","Epoch 28: train loss = 1.328265, test loss = 1.305459\n","Epoch 29: train loss = 1.328149, test loss = 1.304790\n","Epoch 30: train loss = 1.328011, test loss = 1.305062\n","Epoch 31: train loss = 1.327946, test loss = 1.304279\n","Epoch 32: train loss = 1.327892, test loss = 1.304398\n","Epoch 33: train loss = 1.327808, test loss = 1.304651\n","Epoch 34: train loss = 1.327866, test loss = 1.304530\n","Epoch 35: train loss = 1.327762, test loss = 1.304988\n","Epoch 36: train loss = 1.327768, test loss = 1.303799\n","Epoch 37: train loss = 1.327754, test loss = 1.303948\n","Epoch 38: train loss = 1.327679, test loss = 1.304542\n","Epoch 39: train loss = 1.327612, test loss = 1.304236\n","Epoch 40: train loss = 1.327583, test loss = 1.304106\n","Epoch 41: train loss = 1.327612, test loss = 1.304526\n","Epoch 42: train loss = 1.327530, test loss = 1.304290\n","Epoch 43: train loss = 1.327479, test loss = 1.304182\n","Epoch 44: train loss = 1.327568, test loss = 1.303897\n","Epoch 45: train loss = 1.327479, test loss = 1.304063\n","Epoch 46: train loss = 1.327344, test loss = 1.304903\n","Epoch 47: train loss = 1.327480, test loss = 1.303914\n","Epoch 48: train loss = 1.327402, test loss = 1.303943\n","Epoch 49: train loss = 1.327436, test loss = 1.303874\n","Epoch 50: train loss = 1.327385, test loss = 1.304494\n"]}],"source":["## Train the 1-layer neural network using batch training with batch size = 100\n","learning_rate = 1e-02\n","batch_size = 100\n","nepochs = 50\n","reg_strength = 0.1\n","# Create empty array to store training losses over each epoch\n","loss_train_epoch = np.empty(nepochs, dtype = np.float64)\n","# Create empty array to store test losses over each epoch\n","loss_test_epoch = np.empty(nepochs, dtype = np.float64)\n","\n","# Neural network architecture ()\n","dlayer1 = Dense(num_features, num_labels, reg_strength) # define dense layer 1\n","softmax = Softmax() # define softmax activation layer\n","\n","# Steps: run over each sample in the batch, calculate loss, gradient of loss,\n","# and update weights.\n","epoch = 0\n","# Run over each epoch\n","while epoch < nepochs:\n","  # Generate the batches\n","  batch_indices = generate_batch_indices(num_samples, batch_size)\n","  loss = 0\n","  # Run over each batch of samples\n","  for b in range(len(batch_indices)):\n","    # Forward prop starts here\n","    dlayer1.forward(X_train[batch_indices[b], :]) # forward prop dense layer 1\n","    softmax.forward(dlayer1.output) # forward prop softmax activation layer\n","    loss += cce(Y_train[batch_indices[b], :], softmax.output)\n","    # Add the regularization losses\n","    loss += dlayer1.reg_loss\n","    # Forward prop ends and backward prop starts here\n","    grad = cce_gradient(Y_train[batch_indices[b], :], softmax.output)\n","    grad = softmax.backward(grad)\n","    grad = dlayer1.backward(grad, learning_rate)\n","  # Calculate the average training loss for the current epoch\n","  loss_train_epoch[epoch] = loss/len(batch_indices)\n","\n","  # Forward propagation for test data\n","  dlayer1.forward(X_test)\n","  softmax.forward(dlayer1.output)\n","\n","  # Calculate test data loss plus regularization loss\n","  loss_test_epoch[epoch] =  cce(Y_test, softmax.output) + dlayer1.reg_loss\n","\n","  print('Epoch %d: train loss = %f, test loss = %f'%(epoch+1, loss_train_epoch[epoch], loss_test_epoch[epoch]))\n","  epoch = epoch + 1"]},{"cell_type":"markdown","id":"8GWSFNvg8arf","metadata":{"id":"8GWSFNvg8arf"},"source":["---\n","\n","Plot training and test loss vs. epoch\n","\n","---"]},{"cell_type":"code","execution_count":32,"id":"S72SmRqD8dca","metadata":{"id":"S72SmRqD8dca","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"ok","timestamp":1736965564339,"user_tz":-330,"elapsed":644,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}},"outputId":"a563111c-ec49-443a-9fd6-b551b00b0aa3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 400x400 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAFeCAYAAACIBhjdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHy0lEQVR4nO3dd1xT9/4/8FeQocaAAwWhilvcWmfd1as/O/FaRTtukd72ttXWau1eoLdfW+t177bW0aG1dduqrQM3rroVRwVEFBAB2dP374+TBAIBQ0hMAq/n4/F+kJxzcnifk+S88zmfM1QABEREVGU52ToBIiKyLRYCIqIqjoWAiKiKYyEgIqriWAiIiKo4FgIioiqOhYCIqIpjISAiquJYCIiIqjgWArKKPXv2QMQyJ607OzsjJCQEly9fRnZ2NkQEAQEBFpm3PfHy8sKKFStw/fp15OfnQ0Tg4eFh67Tslohgz549tk7DQFBQEEQEQUFBJcaNGTMGJ06cQGpqKkQEs2fPBgBERkYiMjLyQadqwNmSM/Pz80NUVBS2b9+Oxx57zJKzrpJM2ZCqVKoHkIltTZ48GaGhodi7dy/Wrl2LvLw8REREPPA8Hn/8cYwbNw7du3dHnTp1cPfuXcTFxeHo0aPYtGkTNm/eXKH5r1ixAkOHDsXq1atx9epViAiys7P1G4mmTZtaYjHsVo0aNfDKK69g+PDhaN++PWrXro20tDRcuHABW7duxbJly5CYmGjrNM3Sq1cv/Pjjj7h27RoWL16MzMxMhIeH2zotPYsWArK8xMRELFiwwNZp2NSTTz6JtLQ0DBkyBHl5eTbJ4bPPPsOUKVOQkZGBrVu3IioqCs7OzmjXrh1Gjx6NVq1aVagQuLi4YMiQIdi5cydeeOEFC2buGDp27IhNmzahSZMmiIqKwubNmxEfHw93d3f06tULX375JT788EP4+PggMzPT1umWasOGDQgPD8etW7cMhj/xxBNwcnLCiy++iMOHDxuMGzx48INM0SgWAjuXmJiIKVOm2DoNm/Lx8cGdO3dsVgT8/Pzw2Wef4fr16+jVq1eJL3n16tXRs2fPCv0Pb29vVKtWDTdv3qzQfByRr68v/vjjD3h6euLtt9/G3Llzce/ePYNpOnfujAULFsDFxcVGWZomNTUVqampJYb7+PgAgNH399q1a1bPyxRiqfDz8xMRkW3btpk0fePGjeXbb7+VGzduSE5OjsTExMi3334rjRo1KjGtt7e3zJkzRy5fviyZmZmSnJwsFy5ckMWLF4u7u7t+Ond3d5kyZYqcP39e0tLS5O7du3LlyhVZsWKFNG7cuMx8+vbtKyIiy5YtMzq+fv36kpubKwcOHCh3XuaEiMjFixdNnj4yMlIiIyPFw8NDlixZIrdu3ZKsrCz566+/ZMyYMUZfU7NmTQkNDZWLFy9KVlaW3LlzR7Zu3Sq9e/cu9f+MHTtW9u3bJ8nJyZKRkSGXL1+WJUuWGLxve/bsERERZ2dnCQkJkcjISMnOzpZLly7J66+/btLyhISEiDGRkZEl8gkPD5e0tDRJS0uT8PBwCQoKKjG/AQMGiIhISEiIPPLII7Jjxw5JTk4WUfbBlRqjRo0SEZHZs2eX6/0zdd3q1lVxy5cvNzpctwzGlmn37t2SmpoqCQkJsnDhQqlevboAkMcff1wOHTok6enpEhcXJ9OnT5dq1aoZ5OHu7i7vvfeehIWFSWxsrOTk5EhsbKysXLlSmjVrZjBt3bp1JSYmRlJTU6V58+YmjzMWK1asEBGRqVOnljldtWrVRKVSGXw/9uzZYzBNy5YtZfr06XLixAlJTEyUrKwsuXTpknzxxReiVqutvl0JCgoSEdF//nTvjzF+fn4G31tjyxwcHCwHDhyQu3fvSkZGhhw7dkyCg4NL/a4MGDBAgoKC5MSJE5KRkVFi/ZQR5m+oikd5CkHLli0lPj5eREQ2bdok06ZNk82bN4uISHx8vLRs2VI/bY0aNeTvv/+WgoIC2bZtm0yfPl1mz54tGzdulPT0dIMP2+HDh0VEZP/+/TJz5kyZMWOGrF27VpKSkmTw4MH3zevatWuSkpIibm5uJcZNmDBBREReffXVcudlToiUvxDExsbKsWPH5OLFi/LVV1/JwoUL5fbt2yIi8sYbbxhM7+bmJuHh4SIicvz4cfniiy/ku+++k4yMDMnLy5ORI0caTK9SqWTt2rUiIhITEyOLFi2SL7/8UtasWSNJSUkSEBCgn1a3cfvll18kOjpalixZYpDLyy+/fN/lGTBggISEhEhycrIkJydLSEiIhISEyFtvvaWfZu7cufp85syZI3PmzJGYmBgREZkzZ06J+YmI7NixQ3JycmT79u0yffp0Wb16dZl5DBo0SEREtm7davJ7UZ51GxQUJLNnzxYRkZMnT+qXMyAgwOjyh4SEyIABAwyW6ffff5fMzEzZsGGDzJgxQ44fPy4iIt9//70EBgZKZmamrF69WmbOnCkREREiIvLpp58a5NyzZ0/Jzs6Wbdu2yYIFC2T69OmyadMmycvLk8TExBI/pB599FHJz8+XI0eOiLOzs374hg0bRETkxRdfvO96qlGjhmRnZ0tGRka5fzgZKwTvv/++JCYmyi+//CIzZ86U2bNn67cJhw4dMsjTGtuV4oXAz89PQkJC5OTJkyKi/JjQvYceHh76762xQvDjjz+KiMilS5dk8eLFMnfuXLlw4YKIiMyYMcNgWl0h2Lp1q2RkZMhPP/0kX3zxhXz++eemrk/zN1TFozyFYNeuXSIi8sorrxgMf/3110VEZOfOnfphTz75pIiIzJo1q8R81Gq1uLq6CgBp3769iIisX7++xHSurq5GfxEUj6lTp4qIyKhRo0qMO3bsmGRnZ0udOnXKlZe5ISJy+/Ztgw1A0Rg9erTB9JGRkSIiEhYWJi4uLvrhvr6+kpCQIFlZWeLj46Mf/umnn+o3FkXn07lzZ8nOzpakpCSpVauWfvj48eNFROTPP//U/9LURfXq1fXrBSgsBIcPHxaNRqMf3qpVK8nNzTWrpVN8eL9+/URE5Pz58wYbkdq1a+s3dn379tUPL/rrbOzYsSb/f7VaLVFRUSIismXLFnn++ecNfqgYi/KuW913Z/ny5SYvf/Flevrpp/XDnZ2d5dSpU1JQUCAJCQnSrVs3/bhatWpJXFycJCYmGmwY3d3dDd5DXQwcOFDy8/Pl66+/LjFu2rRpIiLy5ZdfGnx/f/zxR5PWbf/+/UVEZN++fWZ9P4oXAh8fH4PPfvH347nnntMPs8Z2pXgh0IWudadrBdzv/X355ZdFRNk7UfQ9cnFxkU2bNomIyMMPP6wfrisEaWlp0r59+3KvS5jxglLD1ELQqFEjERE5d+5ciXEqlUpf9R566CGDN+z//u//ypyv7g0z9UNoLFq2bCkiSiul6HB/f/8SHwZT8zI37mfDhg0lPlAiYnS3zscffywiIm+//bZ+2NWrVyUnJ0d8fX1LTL906VIREXnhhRf0w86fPy95eXnSokWL++auKwQDBw4sdVzRDWFZUdqG8NtvvxUR40X72WefFRGRb7/9Vj9Mt9E8fvx4ud+Lzp07y9mzZw3Wf3JysmzevFmGDx9eYvryrtuKFoJdu3aVGPfJJ5/oNyalrbsmTZqYtPynT5+Wa9eulRju7OwsR44ckfz8fHnjjTckIyNDrl27ZlD8y4rAwEAREfnpp5/M+n6YuuujTp06IiLy3Xff6YdZY7tiqUJw6tQpSUtLK/GDq2g+RVsFukIwc+bMcq9HAGKT8wg6d+4MANi7d2+JcSKCffv2GUy3b98+3Lx5Ex988AG2bt2K1157DW3atCnx2osXL+L06dN47rnnsHfvXkyaNAldunQp1yGWV65cwZEjRzBs2DDUq1dPP1x3JMf333+vH2ZqXhUREREBlUplNP75z3+WmD4vL6/EUQkAsH//fgBAly5dAAAajQbNmzfH1atXERsbW2J63fHZuvdArVajbdu2iIyMxNWrV03O/8SJEyWG3bhxAwBQu3Ztk+djjG5ZwsLCSowrnn9Rx44dK/f/OnXqFDp06IDevXvj448/xvr165Gbm4unnnoKGzZsMPhclHfdWsKpU6dKDNN1apc1TteJqTNgwABs2LABN2/eRG5uLkQEIoKOHTuWmBYA8vPz8eyzzyIzMxPz58+Hq6srnn/+eaSlpVV8ocwUHByMvXv34s6dO/rzMZKSkgAYLu+D3K6UR40aNdChQwekpKTg/fffR0hIiEGMGTMGAODv71/itUePHjXrf9rkqCF3d3cAQHx8vNHxug+pbrrU1FT06tULU6dOxVNPPYUnnngCAHD9+nV8+eWXWLx4MQCgoKAAgwYNQmhoKJ555hnMmjULAJCQkIAFCxbg//7v/0ocjWDM999/j549e2L06NFYtGgRAOD5559HUlISfvvtN/10pub1ICUmJho9/0C3rnUnKJX3PdC9ztiGrSzGNgj5+fkAgGrVqpVrXsW5u7ujoKAAt2/fLjEuPj4e9+7d0+dffJy5Dh8+bFBoAwICsGrVKrzwwgtYt24dNm7cWO51awnGjlTRreeyxhU9CmfkyJH4+eefkZ6ejh07diAqKgqZmZkQEYwdOxZNmjQx+r+vXbuG06dPo2/fvjhx4oTRHyKliYuLA6AcOWQJ8+bNw5tvvonr169j8+bNuHXrFnJycgAAoaGhcHNz00/7oLcrpqpTpw6cnJzw0EMPITQ0tNTp1Gp1iWHmfrZt0iLQfTC9vLyMjvf29jaYDgBiYmIQHByM+vXro3Pnznjvvffg5OSERYsW6SskACQlJWHChAnw9fVFmzZtMH78eCQlJWHq1Kl47733TMpvzZo1yM3N1bcC+vfvjyZNmmDt2rXIzc01mNbUvB4UT09Po79UdOv67t27AMr/HuheZ6kvrCWkpqaiWrVqqF+/folxDRo0gJOTk9GNoLFCaa5NmzbpzxAdNGiQPi+gfJ9vexAaGors7Gx07doVgYGBeO+99xAaGoopU6YgOzu71Ne9/fbb6Nu3LxITE9GzZ0+8/vrrJv/PY8eOIScnB926dYNGo6lQ/vXr18f48eNx+vRp+Pv7Izg4GB999BGmTJmCJUuWGH3Ng9yumEr3uTh+/HipewNUKpX+81aUuZ9tmxQCXVO1f//+Rsfrhhtr0ooITp8+jRkzZuDZZ58FADz99NNG5xMREYFFixZhyJAhZU5X3J07d7B9+3Y88sgjaN68ub4g/PDDD6W+pjx5WZOLiwseeeSREsP79esHADh58iQA5Zf633//jRYtWhht8g8cOBBA4XuQkZGB8+fPo2nTpmjRooV1ki8n3bLoci2qeP7WlJ6ebvC8vOv2fgoKCircejJF8+bNcfHixRK7/ry9vdGsWTOjr+ncuTOmTZuGiIgIdOjQAdeuXcP//vc/tG3b1qT/mZWVhTVr1qBmzZqYPHlymdNWq1atzN0xzZo1g5OTE3bu3ImsrCyDcbrPf2kexHbFVOnp6bhw4QLatGnzwC4xYpNCEBMTg927d6N9+/Z46aWXDMb95z//Qdu2bbFr1y79vuS2bduiQYMGJeaj+8Wl+7Xi5+cHPz+/+05nCt0+35dffhmjRo3CtWvXcPDgQYNpTM0LUPb7tW7dGo0aNTI5B3NNmzbNoMnv6+uLt956C9nZ2VizZo1++MqVK+Hq6oovvvjC4PUdOnTA2LFjkZKSgo0bN+qHL1y4EM7Ozli0aBGqV69u8Bo3NzfUqVPHOgtUipUrVwIAQkJCDH5Nuru7IyQkxGCaiujevTv+9a9/GexW0PH09MTLL78MADhw4IBBbuVZt2VJSkqCp6en0f9vSdHR0WjRooXBZ9rNzQ2LFy+Gq6trielr1qyJ1atXAwCeffZZxMXF4bnnnoOLiwtWr15tcr4ff/wxEhIS8PHHH+PNN980urHv0KEDwsLCytydFh0dDQDo3bu3wTx8fX1LvA+AbbYrppo3bx7UajW++eYb1KxZs8T4Jk2aGM3JXFbpI+jQoQOWL19udFxERASmT5+O119/HQcOHMA333yDp556ChcuXEC7du0QEBCAhIQEg+blkCFDMGPGDBw8eBCXL1/GnTt30KxZMzz99NPIysrCwoULASi/TtavX4+jR4/iwoULiIuLg6+vL4YPH46CggJ9E94UW7ZsQUpKCt5++224urpi3rx5JaYxNS8A6NGjB8LCwhAWFoZHH33U5Dw8PT31GzVjlixZYrBf8ObNm1Cr1Thz5gy2bNkCtVqNwMBAeHp64s033zQ4s/Grr77CE088gRdffBFt2rTBrl270KBBA4wePRrOzs545ZVXDH7tLl68GAMGDMDo0aNx5coVbN68GampqWjcuDH+3//7f/j3v/+NTZs2mbxsFbV//37MmzcPEyZMwLlz57Bu3TqoVCo888wzaNSoEebOnavvJK8IHx8frFq1CgsWLMC+ffsQERGB/Px8+Pn54cknn4RGo8HWrVvxyy+/6F9T3nVblt27d6N79+7Ytm0b9u/fj9zcXOzbt88iy1bU/PnzsWDBApw8eRK//vornJ2dMWTIEKhUKpw6dapE5/bcuXPh7++PyZMn61s3R44cwZQpU/D5559jxowZmDBhwn3/b2xsLIYOHYqNGzdi3rx5mDRpEnbt2qW/xESPHj3QvXt3pKamlnl2eVxcHH799VeMHDkSx48fx65du+Dl5YUnn3wSu3btKtGStcV2xVRLly5Fr169MHbsWPTp0wc7d+7EzZs34eXlBX9/f/Ts2RPPPfecvvhZglmHGxkL3SFwZSl6uFfjxo1l2bJlEhsbK7m5uRIbGyvLli0rceKKv7+/zJ49W06cOCG3b9+WrKwsuXr1qixfvlzatGmjn87X11emTZsmhw4dkri4OMnOzpaoqCj59ddfpWfPnuVenq+//lqft7Hjxk3NCyg8zK8cZ/rdd12KiHTq1KnEYWi1a9c2OLP45MmTZZ5ZPGXKFImIiNAf3/7bb79Jnz59Ss3rpZdekkOHDklaWpqkp6fLpUuXZNGiRfrDfYHCQ0SNvb6sQ+mMRVmHTwLKmcVHjhyR9PR0SU9PlyNHjhg9T6DoWbjl+RzUqlVLnnvuOVm5cqWcPXtWkpKSJDc3V+Lj4+XPP/+U4OBgcXJyqtC6LevwUbVaLUuXLpXY2FjJy8szWIaylqm0QxkBwzNRiw7/z3/+I2fPnpXMzEy5efOmfPPNN+Lp6Vni/RwxYoSIKCfnFZ+3SqWSsLAwERF54oknTF7PNWrUkAkTJsiePXskISFBcnNzJSkpSQ4ePCgffvih1K1bt8T3o/j3Sa1Wy4wZM+TatWv6s4o//vhjcXZ2LjG9NbYrljp8VBejRo2SP/74Q+7cuaO/+sLu3btl0qRJUq9evfu+n6aGSvuAKoGqcpVKIrIs3o+AiKiKYyEgIqriWAiIiKo49hEQEVVxbBEQEVVxLARERFUcb1VpIh8fH5teUZGILE+j0VTJ24MWx0JgAh8fn3JfdZOIHIOvr2+VLwYsBCbQtQR8fX3ZKiCqJDQaDWJjY/mdBgtBuaSlpfFDQ0SVDjuLiYiqOBYCIqIqjoWAiKiKYx8BkR2rWbNmqbcfpdKJCBITE5GZmWnrVBwCCwGRHVKpVAgODjZ6G04yXVhYGJYvX27R+1RXRiwERHYoODgYAwYMwM8//6y/IxqZztnZGf7+/ggMDAQAfPfddzbOyL6xEBDZGbVajYEDB+Lnn3/Gb7/9Zut0HNbff/8NABg9ejTWrFnD3URlYGexxbUA0BlALRvnQY6qXr16AJT7e1PF6Nahp6enjTOxbywEFrcJwEkAXW2dCDkoXccwdwdVnG4dsrO9bCwEFpej/etq0yyIiEzFQmBxudq/LAREFRUZGYm33nrL1mlUeiwEFqcrBG42zYLoQRKRMiMkJMSs+Xbv3h1ff/21hbOl4njUkMWxRUBVj7e3t/7x6NGjMXXqVLRu3Vo/LD093WD6atWqoaCg4L7zTUxMtFySVCq2CCyOfQRU9cTHx+vj7t27EBH9c39/f6Snp2PYsGE4fvw4cnJy0LdvXzRr1gwbN25EXFwc0tLScPToUQwePNhgvsV3DYkI/v3vf2P9+vXIyMjA5cuX8dRTTz3oxa10WAgsji0CsoaaNgrL+fLLL/HBBx+gTZs2OHPmDGrVqoXff/8dgwcPRpcuXbB9+3Zs2bIFjRo1KnM+ISEhWLt2LTp27Ijff/8dP/74I+rUqWPRXKsa7hqyOPYRkKXVBJBho/+tBmCZE7E+++wz7Ny5U/88OTkZZ86cMRj/z3/+E08//TQWLlxY6nxWrFiBNWvWAAA++ugjvPXWW+jRowd27NhhkTyrIrYILI4tAiJjjh8/bvBcrVZjxowZuHDhApKTk5GWloY2bdqgcePGZc6naPHIzMzE3bt30aBBA6vkXFWwRWBxLARkaZlQfpnb6n9bRkaGYavmf//7H4YMGYJ33nkHV69eRVZWFn799Ve4upb93cnLyzN4LiJwcuJv2opgIbA4dhaTNVS+6+T06dMHK1aswMaNGwEoLYQmTZrYNKeqimXU4tgiIDLFlStXMGLECHTq1AkdO3bETz/9xF/2NsK1bnHsLCYyxdtvv43k5GQcOnQIW7ZswY4dO/DXX3/ZOq0qibuGLI4tAqraVq5ciZUrV+qf79271+hF36Kjo0ucN7Bo0SKD502bNjV4bmw+PHS04tgisDgWAiJyLCwEFsfOYiJyLCwEFscWARE5FhYCi2NnMRE5FhYCi2OLgIgcCwuBxbGPgIgcCwuBxbFFQESOhYXA4thHQESOhYXA4tgiICLHwkJgcSwERORYWAgsjp3FVPVY6+b1unkHBARYMFsqjtcasji2CKjqKe/N68m+sEVgcewspqqnrJvXx8fHY8yYMbhw4QKysrJw8eJFvP766/rXuri4YP78+bh58yaysrIQFRWFDz74AIBy83oA2LhxI0RE/5wsiy0Ci2OLgCzPsreRN50lbofz3HPPYerUqXjjjTdw8uRJdOnSBd988w0yMjKwatUqTJgwAU8//TQCAwNx/fp1NGrUSH8D++7du+P27dsYO3Ystm/fjoKCAgtkRMWxEFgcCwFZlqPfun7KlCmYPHkyNmzYAACIiopC27Zt8eqrr2LVqlVo3Lgxrly5ggMHDgAArl+/rn9tYmIiACAlJQXx8fEVzIRKY1e7hvr164fNmzcjNjbWpA6iAQMGGO2Y8vLyMphu3LhxiIyMRFZWFsLDw9G9e3crLgU7i4l0atasiRYtWmDZsmVIS0vTxyeffILmzZsDAFasWIHOnTvj0qVLmDt3LoYMGWLjrKseu2oRqNVqnD59Gt99953+14MpWrVqhdTUVP3zhIQE/ePAwEDMmjULr732Go4cOYKJEydix44daN26NW7fvm3R/BVsEZBlOfKt62vVqgUAeOWVV3DkyBGDcbrdPCdPnkTTpk3x2GOP4R//+AfWrl2LnTt3YtSoURX871QeYo8hIhIQEFDmNAMGDBAREQ8Pj1KnCQ8Pl/nz5+ufq1QquXHjhrz//vsm56LRaERERKPRmDC9pwCiDZXN1yPD8cLPz09WrVolfn5+Ns/FnAgKCpLk5GT98xs3bsgnn3xi8uuHDh0qIiJ16tQRAJKTkyMjRoyw+Los3/e6coddtQjMderUKbi5ueHcuXMIDQ3FoUOHAChHI3Tt2hVffPGFfloRwc6dO/HII4+UOj9XV1e4uRUe9aPRaMqRTW6Rxy7FnhNVPSEhIZg3bx7u3r2L7du3w83NDd26dUOdOnUwe/ZsTJo0Cbdu3cLJkydx7949jBo1Crdu3UJKSgoApU9h8ODBOHjwIHJycvTDyXLsqo+gvG7duoVXX30VzzzzDJ555hnExMQgLCwMXbp0AQB4enrC2dm5RCdTfHy8wXHPxX344YdITU3VR2xsbDmyyinymLuHiJYtW4aXX34ZwcHBOHv2LPbu3YuxY8fqDwVNS0vDe++9h+PHj+PYsWNo0qQJHn/8cYgIAGDy5MkYMmQIYmJicPLkSVsuSqVm82aJsTBl15CxCAsLk1WrVgkAadiwoYiI9OrVy2Ca6dOnS3h4eKnzcHV1FY1Gow8fH59yNCGdBPpdQ3Vtvh4ZjheOvmvInoK7hkyLSrFrqKijR4+ib9++AJRDz/Lz80scReTl5YW4uLhS55Gbm4vcXHN36dwDkA+lH54nlRGR/XPoXUPGdO7cGbdu3QIA5OXl4cSJExg8eLB+vEqlwuDBg3H48GErZsEjh4jIcdhVi0CtVqNFixb6502bNkWnTp2QlJSEmJgYTJs2Db6+vggKCgIAvPXWW4iMjMT58+dRvXp1vPzyyxg0aBCGDh2qn8esWbOwcuVKHD9+HEePHsXEiROhVquxfPlyKy5JLpTTgFgIiMj+2VUh6NatG8LCwvTPZ8+eDUA54SQ4OBgNGzZE48aN9eNdXV0xc+ZM+Pr6IjMzE2fOnME//vEPg3msXbsW9evXx9SpU+Ht7Y1Tp05h2LBhBucaWB5PKiMix2Lzjgp7j/J3Kl0XQAToYvPcGY4XjRs3llWrVknz5s1tnoujR/PmzWXVqlXSuHHjEuPYWVwYla6PwD7wCqRkvjt37gAA/P39bZyJ49OtQ901i8g4u9o1VHmws5jMl5GRgbCwMAQGBgIAIiIikJ+fb+OsHIuzszP8/f0RGBiIsLAwZGZa4jqqlRcLgVWwEFDF6A5mGD16tI0zcWxhYWFWPjCkcmAhsAp2FlPFiAi+++47rFmzBp6enlCpVLZOyaGICBITE9kSMBELgVWwRUCWkZmZaXB9fiJrYGexVbCzmIgcBwuBVbBFQESOg4XAKthHQESOg4XAKtgiICLHwUJgFewjICLHwUJgFWwREJHjYCGwChYCInIcLARWwc5iInIcLARWwRYBETkOFgKrYGcxETkOFgKrYIuAiBwHC4FVsBAQkeNgIbAKdhYTkeNgIbAKtgiIyHGwEFgFO4uJyHGwEFgFWwRE5DhYCKyCfQRE5DhYCKyCLQIichwsBFbBPgIichwsBFbBFgEROQ4WAqtgISAix8FCYBXsLCYix8FCYBVsERCR42AhsAp2FhOR42AhsAq2CIjIcbAQWAULARE5DhYCq2BnMRE5DhYCq2AfARE5DhYCq8gt8tjFZlkQEZmChcAqihYC7h4iIvvGQmAVOUUesxAQkX1jIbCKewAKtI9ZCIjIvlWoELi6uqJXr154+umnUa9ePUvlVEmww5iIHIPZheDNN9/ErVu3cODAAaxfvx4dO3YEANSrVw+3b99GcHCwxZJ0TDyXgIgcg1mFYOzYsZgzZw62b9+Of//731CpVPpxd+7cwe7duzFmzBiLJemYWAiIyDGYVQgmT56MTZs24fnnn8eWLVtKjD9x4gTatWtX4eQcG08qIyLHYFYhaNGiBbZt21bq+KSkJLP6DPr164fNmzcjNjYWIoKAgACTX9u7d2/k5eXh5MmTBsNDQkIgIgZx8eLFcudWfmwREJFjMKsQpKSkwNPTs9Txbdu2RVxcXLnnq1arcfr0aYwfP75cr/Pw8MCqVauwa9cuo+PPnTsHb29vffTt27fcuZUfO4uJyDE4m/Oi33//Hf/5z3+waNGiEuPatm2LV155Bd99912557t9+3Zs37693K9bsmQJfvrpJxQUFGD48OElxufn5yM+Pr7c860YtgiIyDGY1SL45JNPUK1aNZw7dw6ff/45RARBQUH4/vvvcfz4cSQkJGDq1KmWztWosWPHolmzZpgyZUqp07Rs2RKxsbH4+++/8cMPP6BRo0ZlztPV1RUajcYgyo+FgIgch5gT9evXl2+++Ubu3LkjBQUFUlBQICkpKbJs2TKpX7++WfMsGiIiAQEBZU7TokULiYuLk5YtWwoACQkJkZMnTxpMM2zYMBk5cqR06NBBhg4dKgcPHpSoqCipVatWqfMNCQkRYzQaTTmW4YAAIkDZy8BgMGwTGo3GjO91pY2Kz8TT01MaNGggKpXKYondrxA4OTnJ0aNH5dVXX9UPM1YIioeHh4ekpKTISy+9VOo0rq6uotFo9OHj42PGB2a3ACLAKFu/wQwGw0iwEBSGWX0ExSUmJlpiNuWi0WjQvXt3dOnSBQsWLAAAODk5wcnJCXl5eRg6dCj27NlT4nV3797F5cuX0aJFi1LnnZubi9zc3FLHm4adxUTkGMwqBJ9++ul9pxERfP755+bM3iSpqalo3769wbBx48Zh0KBBGDlyJCIjI42+Tq1Wo3nz5vj++++tlpuCfQRE5BjMKgShoaGljhMRqFQqswqBWq02+KXetGlTdOrUCUlJSYiJicG0adPg6+uLoKAgiAjOnz9v8PqEhARkZ2cbDJ8xYwa2bNmC6Oho+Pj4YMqUKSgoKMDq1avLlVv58YQyInIMZhWCatWqlRimUqng5+eH8ePHo3///njsscfKPd9u3bohLCxM/3z27NkAgBUrViA4OBgNGzZE48aNyzXPhx56CKtXr9ZfA+nAgQPo1avXA9idxRYBETkGFZTOAov64YcfoFKp8Pzzz1t61jah0WiQmpoKd3d3pKWlmfiq5QDGAngPwAyr5UZE5jHve105WeV+BPv27cPjjz9ujVk7ELYIiMgxWKUQdOvWDffu3bPGrB0ICwEROQaz+gj+9a9/GR1eu3Zt9O/fHyNGjMC3335bocQcHzuLicgxmFUIVqxYUeq4xMREfPnllw/sEhP2iy0CInIMZhWCpk2blhgmIkhOTkZ6enqFk6oceEIZETkGswrB9evXLZ1HJcQWARE5Bqt0FhPAQkBEjsKkFkFBQQFEyne6gYjAxcXFrKQqB3YWE5FjMKkQTJ06tdyFgNgiICLHYFIhKOumL1QadhYTkWNgH4HVsEVARI6hQvcj8PX1RZcuXeDh4QEnp5I1xfqXerZn7CMgIsdgViFwc3PDypUr8cwzz8DJyUl/6WkABn0JVbsQsEVARI7BrF1D06ZNw4gRI/Dxxx9j4MCBUKlUCAoKwtChQ7Ft2zacPn0anTp1snSuDoZ9BETkOMp9f8vo6GhZunSpAJC6detKQUGBPProo/rxu3btkkWLFtn8PpyWCvPubTpIABHgjM3zZzAYJYP3LC4Ms1oEDRo0wNGjRwEAWVlZAJS7i+msW7cOI0aMMGfWlQh3DRGRYzCrEMTHx6NevXoAlEKQnJyM1q1b68e7u7ujevXqlsnQYbGzmIgcg1mdxUeOHEHfvn3x1VdfAQC2bNmCd999F7du3YKTkxMmTZqE8PBwiybqeNgiICLHUe79SX369JE5c+aIq6urAJCHHnpIIiIipKCgQAoKCuTy5cvSqlUrm+/3slSYty+xjQAiwG2b589gMEoG+wgKw2L3LFapVOjQoQMKCgoQERGBgoICS8zWLph3b9PmAK4CSAXgYb3kiMgsvGdxIbN2Dbm7uyM1NdVgmIjgzJkzFkmqcuCuISJyDGZ1FickJGDjxo149tlnDY4WoqLYWUxEjsGsQjBr1iy0a9cOP/zwAxISEvDLL79g5MiRPFLIgK5F4ASgmi0TISK6L7M7GLp16yYzZsyQyMhIKSgokNTUVPnpp58kICBAXFxcbN4BYqkwr1OppgCijZo2XwYGg2EY7CwuDIt1Fvfq1QujR4/GyJEj0bBhQ6SmpqJu3bqWmLXNmdep5AwgT/u4DoAUq+RGROZhZ3GhCl19tKjw8HAkJiYiOTkZb7/9Ntzd3S01aweVD+AelF1D7CcgIvtV4ULQpEkTjB49GoGBgejUqRPu3buHPXv24Oeff7ZEfg4uF0B1sBAQkT0zqxA89NBDCAwMxOjRo9G1a1eICPbv34/x48dj3bp1SExMtHSeDkpXCHgFUiKyX2YVgujoaIgIwsPDMWnSJPzyyy+Ii4uzdG6VAM8lICL7Z1YhePfdd7F27VrcuHHD0vlUMiwERGT/zCoEs2bNsnQelRRPKiMi+8eb11sVWwREZP9YCKyKt6skIvvHQmBVbBEQkf1jIbAqFgIisn8sBFbFzmIisn9mFYJGjRqhT58+BsM6duyIlStXYs2aNQgICLBIco6PLQIisn9mHT46b9481KpVC0OGDAEANGjQAHv27IGrqyvS0tIwcuRIjBo1Chs2bLBoso6HncVEZP/MahH06NEDf/75p/75iy++iBo1aqBTp07w9fXFrl278M4771gsScfFFgER2T+zCkHdunWRkJCgf/7kk09i7969uHbtGkQE69evh7+/v8WSdFzsIyAi+2dWIbh9+zb8/PwAAB4eHujVqxd27NihH+/s7AxnZ4td4dqBsUVARPbPrEKwc+dOTJgwAZMmTcKqVavg5OSEjRs36se3bdsWMTEx5Z5vv379sHnzZsTGxkJEytXp3Lt3b+Tl5eHkyZMlxo0bNw6RkZHIyspCeHg4unfvXu7czMM+AiJyDOW+rVmDBg3kwIEDUlBQIFlZWTJhwgT9OFdXV7l9+7bMnTu33PMdNmyY/Pe//5Xhw4eLiEhAQIBJr/Pw8JCrV6/K9u3b5eTJkwbjAgMDJTs7W8aOHStt2rSRpUuXSlJSktSvX/8B3NJugQAiQKjNb0XHYDAMg7eqNAjzX+zu7l7i3sTVq1eXjh07Sp06dSqUWHkKwerVq2Xq1KkSEhJSohCEh4fL/Pnz9c9VKpXcuHFD3n///QfwgZklgAgwzdZvMoPBKBYsBIVRoRPKUlNTkZeXZzAsOzsbZ86cQXJyckVmbbKxY8eiWbNmmDJlSolxLi4u6Nq1K3bu3KkfJiLYuXMnHnnkkVLn6erqCo1GYxDmYWcxEdk/swrBoEGDShweGhwcjOjoaMTFxWHWrFlwcrL+ScstWrTAl19+iRdeeAEFBQUlxnt6esLZ2Rnx8fEGw+Pj4+Ht7V3qfD/88EOkpqbqIzY21swM2VlMRPbPrK11aGgoOnXqpH/evn17LF26FLdv30ZYWBgmTJhg9fMInJyc8NNPPyEkJARXrlyx6Ly/+OILuLu768PX19fMObGzmIjsn1nHeLZp0wbr1q3TP//Xv/6F1NRU9OvXD1lZWVi8eDFefPFFfPXVVxZLtDiNRoPu3bujS5cuWLBgAQClODg5OSEvLw9Dhw7FgQMHkJ+fDy8vL4PXenl5lXlrzdzcXOTm5pY63nRsERCR/TOrRaBWq5Gamqp/PmzYMGzfvh1ZWVkAgGPHjunPM7CW1NRUtG/fHp07d9bHkiVLEBERgc6dO+PIkSPIy8vDiRMnMHjwYP3rVCoVBg8ejMOHD1s1PwULARHZP7NaBDExMejevTuWL1+O5s2bo3379pg5c6Z+fN26dZGTk1PGHIxTq9Vo0aKF/nnTpk3RqVMnJCUlISYmBtOmTYOvry+CgoIgIjh//rzB6xMSEpCdnW0wfNasWVi5ciWOHz+Oo0ePYuLEiVCr1Vi+fLkZS15e7CwmIvtnViH48ccf8dlnn8HX1xft2rVDcnIyNm3apB/ftWtXXL58udzz7datG8LCwvTPZ8+eDQBYsWIFgoOD0bBhQzRu3Lhc81y7di3q16+PqVOnwtvbG6dOncKwYcMMLpFhPewjICLHUO5jTqtVqyaff/65/PXXX7J7927p27evflydOnXk1q1b8sEHH9j82FhLhfnHG78ggAiw3ebLwGAwDIPnERSGSvuAyqDRaJCamgp3d3ekpaWV45WBAH4GsAfAIOskR0RmMf97XflU+MpwarUajRo1AqD0HWRkZFQ4qcqDfQREZP/MPuurW7du2L17N5KTk3Hu3DmcO3cOycnJ2LVrF7p27WrJHB0YjxoiIvtnVougR48eCAsLQ25uLr799ltcvHgRgHJ+wbPPPot9+/Zh4MCBOHbsmEWTdTzsLCYix1DujoU///xTrly5Il5eXiXGNWjQQK5cuSJ//PGHzTtALBXmdyr1E0AEuGjzZWAwGIbBzuLCMGvXUM+ePbF06dIS1/ABlGP5v/76a/Tq1cucWVcy3DVERPbPrEJw7969Mu9AVq1aNdy7d8/spCoPdhYTkf0zqxAcOnQI48ePN3pyV6NGjTBu3DgcPHiwwsk5PrYIiMj+mdVZ/NFHH2Hfvn2IiIjAhg0b9GcRt27dGgEBAcjPz8eHH35o0UQdEzuLicgxmNW50KZNG1m/fr2kpaVJQUGBFBQUSFpamqxbt07atGlj884PS4b5nUqNBRABMm2+DAwGwzDYWVwYFT6zWKVSoX79+gCA27dvQ0RQs2ZNeHh44NatWxWZtd0w/wxEbwC3ABTAAufuEZEF8cziQhW+jZiIICEhAQkJCRBRasrEiRMRExNT4eQcn66zuBossKqJiKyCWyerKnpzG/YTEJF9YiGwqqKFgEcOEZF9YiGwqrwij1kIiMg+sRBYHU8qIyL7ZvKhLF26dDF5pj4+PmYlUznlQukfYCEgIvtkciE4fvy4/qig+1GpVCZPW/nxpDIism8mF4Lg4GBr5lGJ8TITRGTfTC4Eq1atsmYelRgLARHZN3YWWx07i4nIvrEQWB1bBERk31gIrI6dxURk31gIrI4tAiKybywEVsdCQET2jYXA6thZTET2jYXA6thHQET2jYXA6rhriIjsGwuB1bEQEJF9YyGwOvYREJF9YyGwOrYIiMi+sRBYHTuLici+sRBYHVsERGTfWAisjoWAiOwbC4HVsbOYiOwbC4HVsUVARPaNhcDq2FlMRPaNhcDq2CIgIvvGQmB1LAREZN9YCKyOncVEZN9YCKyOfQREZN/sqhD069cPmzdvRmxsLEQEAQEBZU7fp08fHDhwAImJicjMzMTFixcxceJEg2lCQkIgIgZx8eJFKy5Fcdw1RET2zdnWCRSlVqtx+vRpfPfdd9iwYcN9p8/IyMCCBQtw5swZZGRkoG/fvli6dCkyMjLwzTff6Kc7d+4c/vGPf+if5+fnWyV/41gIiMi+2VUh2L59O7Zv327y9KdOncKpU6f0z6OjozFixAj069fPoBDk5+cjPj7ekqmWA/sIiMi+2dWuoYrq3Lkzevfujb179xoMb9myJWJjY/H333/jhx9+QKNGjcqcj6urKzQajUGYT9ci8ALgUoH5EBFZj9hjiIgEBASYNG1MTIxkZ2dLfn6+fPLJJwbjhg0bJiNHjpQOHTrI0KFD5eDBgxIVFSW1atUqdX4hISFijEajMWNZ6gmQLIAIMNfm65XBYCih0Wgq8L2udGHzBIxGeQpBkyZNpH379vLyyy9LYmKijBkzptRpPTw8JCUlRV566aVSp3F1dRWNRqMPHx+fCn5gnhRAtPGczdctg8FgISgadtVHYK6oqCgASqewl5cXQkNDsWbNGqPT3r17F5cvX0aLFi1KnV9ubi5yc3NLHV9+WwH8F8CnAL4BcFYbRES2V6n6CADAyckJbm6lH7OvVqvRvHlz3Lp16wFmBQChAHYAqAlgHQCPB/z/iYiMs6sWgVqtNvil3rRpU3Tq1AlJSUmIiYnBtGnT4Ovri6CgIADAuHHjcP36dURERAAA+vfvj3feeQfz5s3Tz2PGjBnYsmULoqOj4ePjgylTpqCgoACrV69+sAuHewCeA3ACQEsAqwD8UzuciMi2bL5/ShcDBgww2km7fPlyASDLly+XPXv26Kd/44035OzZs5Keni4pKSly4sQJee2110SlUumnWb16tcTGxkp2drbExMTI6tWrpVmzZjbcl9hVgCwBRIALAjwvQDWbr3sGo6oF+wgKQ6V9QGXQaDRITU2Fu7s70tLSLDDHkQCWAqirfX4FwDQAPwB4kCe7EVVdlv9eO65K10fgGH4F0ATABwBuQ9lVtBzAdQD/A9DZVokRURXEQmAzaQCmQykIkwHEAWiofXwSwHkAHwJobKP8iKiqYCGwuUwAs6Bs8J8C8DOALABtoewuigawB8BLANxtlCMRVWYsBHYjD8r5BmMAeAMIBrALylFFAwEsg9Jq+AXACyjsXyAiqhgWAruUCmAFgH8A8IPSl3AeQA0oHc3fA0gAsBfKrqR2NsmSiCoHHjVkAvs5uqALlHMPngbQqdi4mwD+1MYuKK0HIiqN/XyvbY+FwAT2+YHR9Sk8BaA/lNZCUbEAjkM5ge0EgGNQjlAiIsBev9e2wUJggvJ8YOoCeAzAjw8kMx03AH0ADAEwFMrhp8b2+l0DcBTAEW2chtJZTVT1sBAUYiEwgakfGGcoe+7rAOgB5Te4baihFIOuALppozVKFocCABEA/tLGWQCXoLQm+LGgyo2FoJBdXWvI0eUD2A7gWQCjYMtCkAHgoDZ03KEUhJ7a6AHlvIV22vhXkWkzAVyGUhROQdm19BeAO1bOm4hsgS0CE5Tnl8M/AawHEAWg6QPIrWK8ATxcJNoAaI7S76QWDeACgFtQOqPjtI9jAcRoHxdYN2UiC2GLoBBbBBa2DUA6lPOFu8OWrQJTxAH4XRs61aCUsFZQTmrTFYnWUA5l9StjfgVQisFNAPFQdpTpIh6FBeQWgLsWXA4iqggWAgvLBrAFyu6hQNh7ITCmAMBVbRQtEBooh682g9KS8Iaya6khgIcA+AJw1T5+yIT/kwWlYNxEYfG4A6VAGIsU7V+2OIgsjbuGTFDeJuRwABug7EhpYt3U7IgKQAMoRcAHQH0AXtphXjAsHrUr8H/SASQXiywoJVgXWVD6SdK1f4tGZpHH6drgkVNVEXcNFWKLwAq2Q7mknB+ULtmjtk3nAREou3/ioXQul6UGCouCT5GoC6VT28NI1NK+tpY2Glkw93tQCkPxgpINILeMyDHyN8fIPLKhHEpQNAq0UfxxXpEogLKrrhqUr2o1ba5Fc8hD6b/lpMjf/PtMS1UZC4EV6HYPPQdl91DVKATlkQUgUhumcoZSJGpDOUBXF7WhFJbqRaImlENo1VCKhu5xzSJ/dQUFUA6r1WijsrsHpSCUVphEO8097WMnKK09J23oXq+bR16R1+oCUHYTumjDWTu8aJErXjRztNO5ofB9dCmSn+7/6XLShUqbU/EcXtLOl0zBQmAlv0ApBKMAvGPjXCqHfABJ2rAUFZQiUgtKEahuJFygbNRcoWykXLR/3YoMK/63Ogw3aDWgfNWKR7Vi4YzCjaeLdljxDZyqyP8x51JhTkXyr8xesXUCDoWFwEp0u4caQzlq/4ht0yGjBEr/QCaUI5scTTUoRaHoLiAdVbEoWoCKFppqRYYX/ZVdtAWgax3ofo3r5uFcbD66AAp3W+l+yVeDYZHTFaOiRTcfJXenFX9d0RZL0VZL8RxyyrkuqzYWAispuntoFFgIyBoKoOxmI6oYXobaitZq/46C8huLiMgesRBY0Q4U7h7qYeNciIhKw0JgRdkANmsfv4rSL9xARGRLLARWtkb7NxjK9Yc+g3J6FRGRvWAhsLKtUG4meQvKKVNTAFyHcrPJNjbMi4hIh4XgAZgF5SzjZwEcgnLA3wtQrv6/Ao5wlVIiqsxYCB6QPCi7ifpAuSvAeihHOwdBuer/QiiXbSMietBYCGzgBIBnoFymegeUTuRxUC5S9zuUy1JU9vM+ich+sBDY0HEAw6Dcen43lBbCYwB+htKnsBjAIzbLjoiqChYCO7AfwGAALQBMhdIyqAPgNSh9ClcBhGrHExFZGu9HYIIHfd1yFYCBUPoPnkHhNTIB4Jw2LgC4qP0bAeWqK0RkOt6PoBCvNWSHBMAebYwDEADl1vJDAbTXRlG3oVzk7jcAf0C5VQsRkanYIjCBvfxyaAClg7kNlLsJtwHQDoZX0S+Acv+DA1B2Kx2CY15Xk8ja7OV7bQ/YInAgCVB+9f9WZJgzgN4AHofS0dwRSgdz0U7mv6HsQroOIEYbUVDOY6jaH38iAlgIHF4+gH3a+ADKHYMHQjlfoTeU3UjNtWHMVQCnAJwE8BeUI5kSrZkwEdkd7hoygSM3Id2h7E5qBuUqqI2h3O23JZSiYUwUgGNQWgyuKLxrcG0oF9K7oo3L2r8sHOSIHPl7bWlsEVRyqQB2aaM4TwCdAHQG0AVAVwD+AJpoY5SJ/+MOlCOYdHEOyklzlrypJBFZDwtBFZaIkkXCHcDDUFoRraHcxPEugBTt31oAWkFpUbSEcg2legD6aqOov6HsajqhfW3RmxsWALgJ4AaUPotbUC7DQUQPHgsBGUgFEKYNU9SAUhjaoPBopk5QioSub2K0CfO5B6XYJGsjBUqLIgFAfJG/WTC8NbwzlE7wCACxJuZMRIZYCKhCsgCc1kZRtVHYsugCpa8hH4W3M3eFclnuRlAutucGoK42zJUO5QJ+16G0ZLKKRD6UVogusqG0SGKLBFDYF1IbSqGJ145L1Y5XQTlktw+UFlB7KK2ZS0XiTrH5aKC0es5AOWu8ojRQ1p2vdv5/QenXcVTuUH5AxMGxl8ORsbPYBOxUsi4VlP4KTyiX1qit/VsXyrkTXkXCDcqGPQfKxlygXMa7Oax7B7h0KAXBS5ufuVKh9KFEQvkV5lYkNFA2ih7avzWhFM2cIqGB4XkjOlehnEz4J4DzKGwx1QCghrILT9dCa6ZdhmQora4k7eMMKOs0W/u/oF3ehtrw1g5L0y5HKpT1kg0gVxs5UIqwrlWXrJ3OWbs8NbU5PQTlB0JnGB7RdgvKuS+HoRzNVgDl8+GkjXtQirounKG8/y2KREPt8t4Pv9eFWAhMwA+M/XOGsoHzh7IhqFEsnKFc1E8Xaii/qh+C8starZ1PAZQNWAqUDZs3lKJUVDqAcCgn7f0FZWPZuki4F5lHCpQNYzMou84sdVXZFCiFKRPKxtTRb4MaC6XoW2o5fKAUlbLwe13IrnYN9evXD++++y66du0KHx8fDB8+HJs2bSp1+j59+mD69Onw9/dHzZo1ER0djaVLl2LOnDkG040bNw7vvvsuvL29cfr0abz55ps4duyYlZeGHqR8KIezXjbz9e5Qfm2mGxlXA0qx8IXy6/YMlIJRXs5Q+lM6aueVUyzSoXSqp2r/ZkLZMBZtNWSisADoaKCcOzJEG74w3C2WBaVT/m8A17R/70BpFdRFYeurJgpbEtWh/EpMgLJBjdNGAQpbLu7ax25QdvW5ah+rYdiy84BSVLO0eWdq//8pKOevnIbSKqkO5ci13tpopV2+e9oQbU7ORUKg7E66Wixul/ouUGnEXmLYsGHy3//+V4YPHy4iIgEBAWVO37lzZxkzZoy0bdtW/Pz85Pnnn5f09HR55ZVX9NMEBgZKdna2jB07Vtq0aSNLly6VpKQkqV+/vsl5aTQaERHRaDQ2X0cMBsMywe+1Qdg8AaNhSiEwFuvWrZNVq1bpn4eHh8v8+fP1z1Uqldy4cUPef/99fmAYjCoc/F4XRqW6H0Hnzp3Ru3dv7N27FwDg4uKCrl27YufOnfppRAQ7d+7EI4+UfssXV1dXaDQagyAiqqwqRSGIiYlBdnY2jh8/joULF2LZsmUAAE9PTzg7OyM+Pt5g+vj4eHh7exubFQDgww8/RGpqqj5iY3mEOhFVXpWiEPTr1w/dunXDa6+9hokTJ2LMmDEVmt8XX3wBd3d3ffj68rbyRFR52dVRQ+aKiooCAJw7dw5eXl4IDQ3FmjVrkJiYiPz8fHh5eRlM7+Xlhbi4uFLnl5ubi9zcXGumTERkNypFi6AoJycnuLkpR2vn5eXhxIkTGDx4sH68SqXC4MGDcfjwYVulSERkV+yqRaBWq9GiReEt2ps2bYpOnTohKSkJMTExmDZtGnx9fREUFARAOT/g+vXriIiIAAD0798f77zzDubNm6efx6xZs7By5UocP34cR48excSJE6FWq7F8+fIHu3BERHbM5ocu6WLAgAFizPLlywWALF++XPbs2aOf/o033pCzZ89Kenq6pKSkyIkTJ+S1114TlUplMN/x48dLVFSUZGdnS3h4uPTo0YOHmTEYVTz4vS4MXmLCBDwVnajy4fe6kF3tGrJ3PJ+AqPLg97kQC4EJdB8Ynk9AVPloNJoq3yLgriET+fj4mPRh0Wg0iI2Nha+vb5X/cD0IXN8PTmVc1xqNBjdv3rR1GjbHFoGJyvthSUtLqzRfFkfA9f3gVKZ1XVmWo6Iq3XkERERUPiwERERVHAuBheXk5CA0NBQ5OTn3n5gqjOv7weG6rrzYWUxEVMWxRUBEVMWxEBARVXEsBEREVRwLARFRFcdCYGHjxo1DZGQksrKyEB4eju7du9s6JYf3wQcf4OjRo0hNTUV8fDw2bNiAVq1aGUzj5uaGBQsWIDExEWlpafj111/RoEEDG2Vcebz//vsQEcyePVs/jOu6crL5JVArSwQGBkp2draMHTtW2rRpI0uXLpWkpCSpX7++zXNz5Ni2bZsEBQVJ27ZtpWPHjrJ161aJioqSmjVr6qdZtGiRREdHy6OPPioPP/ywHDp0SA4cOGDz3B05unXrJteuXZNTp07J7Nmzua4rd9g8gUoT4eHhMn/+fP1zlUolN27ckPfff9/muVWm8PT0FBGRfv36CQBxd3eXnJwceeaZZ/TTtG7dWkREevbsafN8HTHUarVcunRJBg8eLHv27NEXAq7ryhncNWQhLi4u6Nq1K3bu3KkfJiLYuXMnHnnkERtmVvl4eHgAAJKSkgAAXbt2haurq8G6v3TpEqKjo7nuzbRw4UL89ttv2LVrl8FwruvKiRedsxBPT084OzsjPj7eYHh8fDz8/f1tlFXlo1KpMGfOHBw4cADnz58HAHh7eyMnJwd37941mDY+Ph7e3t62SNOhjR49Gg8//LDR/i2u68qJhYAcysKFC9G+fXv07dvX1qlUSg899BDmzp2LIUOG8FISVQh3DVlIYmIi8vPz4eXlZTDcy8sLcXFxNsqqcpk/fz6efPJJPProowY3CYqLi4Obm5t+l5EO1335de3aFV5eXvjrr7+Ql5eHvLw8DBw4EBMmTEBeXh7i4+O5rispm3dUVJYIDw+XefPm6Z+rVCqJiYlhZ7EFYv78+XLjxg1p0aJFiXG6DswRI0boh7Vq1YodmGZErVq1pF27dgZx9OhRWbVqlbRr147ruvKGzROoNBEYGChZWVny4osvir+/vyxZskSSkpKkQYMGNs/NkWPhwoWSnJws/fv3Fy8vL31Ur15dP82iRYskKipKBg4cKA8//LAcPHhQDh48aPPcK0MUPWqI67rShs0TqFQxfvx4iYqKkuzsbAkPD5cePXrYPCdHj9IEBQXpp3Fzc5MFCxbInTt3JD09XdatWydeXl42z70yRPFCwHVd+YKXoSYiquLYWUxEVMWxEBARVXEsBEREVRwLARFRFcdCQERUxbEQEBFVcSwERERVHAsBkQUFBQVBRNC1a1dbp0JkMhYCcji6jW1p0bNnT1unSORQeBlqcliffvopIiMjSwy/evWqDbIhclwsBOSwtm3bhhMnTtg6DSKHx11DVCn5+flBRDB58mRMnDgRUVFRyMzMRFhYGNq1a1di+kcffRT79u1Deno6kpOTsXHjRqN3lvPx8cG3336L2NhYZGdn49q1a1i0aBFcXFwMpnNzc8PMmTORkJCA9PR0rF+/Hp6enlZbXqKKYIuAHJaHhwfq1atnMExE9PcyBoAXX3wRGo0GCxcuRPXq1fHWW29h9+7d6NChAxISEgAAgwcPxrZt23Dt2jWEhoaiRo0aePPNN3Hw4EE8/PDDiI6OBgA0bNgQR48eRe3atfH1118jIiICvr6+GDlyJGrWrGlw+8b58+cjOTkZU6ZMQZMmTTBx4kQsWLAAY8aMeQBrhqj8bH4JVAajPBEUFFTqpamzsrIEgPj5+YmISEZGhvj4+Ohf2717dxERmTlzpn7YX3/9JXFxcVKnTh39sA4dOkh+fr6sWLFCP2zFihWSn58vXbt2vW9uf/zxh8HwmTNnSl5enri7u9t8/TEYxYMtAnJY48aNw+XLlw2GFRQUGDzfuHEjbt68qX9+7NgxhIeH4/HHH8fkyZPh7e2NLl26YPr06UhOTtZPd/bsWfz55594/PHHAQAqlQrDhw/Hli1bTOqX+Prrrw2e79+/H2+//Tb8/Pxw9uzZci8rkTWxEJDDOnr06H03yleuXCkx7PLlywgMDASg9CUAwKVLl0pMd/HiRQwbNgw1a9ZErVq14OHhgXPnzpmU2/Xr1w2e64pMnTp1THo90YPEzmIiKyjeMtFRqVQPOBOi+2OLgCq1li1blhjWqlUrREVFAYC+I7h169YlpvP398ft27eRmZmJrKws3L17F+3bt7dqvkS2wBYBVWrDhw+Hj4+P/nn37t3Rq1cvbNu2DQAQFxeHkydPIigoCB4eHvrp2rVrh6FDh+L3338HAIgINm7ciKeeeoqXj6BKhy0CcliPPfaY0WP9Dx06hHv37gFQzjI+cOAAFi9eDDc3N0ycOBGJiYn46quv9NO/++672LZtGw4fPoxly5bpDx+9e/cuQkND9dN99NFHGDp0KPbu3Yuvv/4aFy9eRMOGDTFq1Cj07dvX4PBRIkdj80OXGIzyRFmHj4qIBAUF6Q8fnTx5skyaNEmio6MlKytL9u7dKx06dCgxz0GDBsn+/fslIyNDUlJSZNOmTeLv719iukaNGsmKFSskPj5esrKy5OrVqzJ//nxxcXExyK34IaYDBgwQEZEBAwbYfP0xGEbC5gkwGBaPooXA1rkwGPYe7CMgIqriWAiIiKo4FgIioipOBWUfERERVVFsERARVXEsBEREVRwLARFRFcdCQERUxbEQEBFVcSwERERVHAsBEVEVx0JARFTFsRAQEVVx/x+xZ/pbHmamgQAAAABJRU5ErkJggg==\n"},"metadata":{}}],"source":["## Plot train and test loss as a function of epoch:\n","fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n","fig.tight_layout(pad = 4.0)\n","ax.plot(loss_train_epoch, 'b', label = 'Train')\n","ax.plot(loss_test_epoch, 'r', label = 'Test')\n","ax.set_xlabel('Epoch', fontsize = 12)\n","ax.set_ylabel('Loss value', fontsize = 12)\n","ax.legend()\n","ax.set_title('Loss vs. Epoch for Softmax Classifier', fontsize = 14);"]},{"cell_type":"markdown","id":"oqR5Q5qS8mWm","metadata":{"id":"oqR5Q5qS8mWm"},"source":["---\n","\n","Assess model performance on test data\n","\n","---"]},{"cell_type":"code","execution_count":35,"id":"Su24oMSJTxEb","metadata":{"id":"Su24oMSJTxEb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736965681176,"user_tz":-330,"elapsed":1455,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}},"outputId":"23463c04-d220-4fca-a128-c930659cefbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test data = 85.12\n","[[ 939    0    2    5    1    9   19    1    4    0]\n"," [   0 1105    6    3    0    1    4    0   16    0]\n"," [  19   63  792   30   27    0   27   27   45    2]\n"," [   5   18   21  873    1   22    9   22   30    9]\n"," [   1   19    3    0  880    1   22    3    7   46]\n"," [  25   53    0  108   31  589   35   22   17   12]\n"," [  20   15   11    1   13   17  879    1    1    0]\n"," [   3   53   20    2   15    0    2  902    5   26]\n"," [  12   48   12   55   14   17   19   15  761   21]\n"," [  20   19   10   12   82    7    4   52   11  792]]\n"]}],"source":["## Assess model performance on test data\n","dlayer1.forward(X_test)\n","#alayer1.forward(dlayer1.output)\n","#dlayer2.forward(alayer1.output)\n","softmax.forward(dlayer1.output)\n","ypred = np.argmax(softmax.output, axis = 1)\n","ytrue = np.argmax(Y_test, axis = 1)\n","print('Accuracy on test data = %3.2f'%(np.mean(ytrue == ypred)*100))\n","# Print confusion matrix\n","print(confusion_matrix(ytrue, ypred))"]},{"cell_type":"code","source":["## Plot a random test sample with its predicted label printed above the plot\n","test_index = np.random.choice(X_test.shape[0])\n","fig, ax = plt.subplots(1, 1, figsize = (2, 2))\n","print(f'Image classified as {ypred[test_index]}')\n","ax.imshow(tf.reshape(X_test[test_index], [28, 28]).numpy(), cmap = 'gray');"],"metadata":{"id":"GO70lwOTuH74","colab":{"base_uri":"https://localhost:8080/","height":234},"executionInfo":{"status":"ok","timestamp":1736965691816,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sinchana Venugopal","userId":"08551745987462219121"}},"outputId":"0942469a-0f82-4f24-c0db-d29c53e3b44e"},"id":"GO70lwOTuH74","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Image classified as 3\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 200x200 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAMkAAADICAYAAABCmsWgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAO7klEQVR4nO3df0zU9R8H8Od9RY5Fn8MZcAiZ2QyBWZgUjPJHSn/YMpEV2JgJrj8qf83WUmktY7qYtZLtgGmurNUftUk4ZlOD/LFQQEbLLbdcNXB6yBUecafAnaz394/vvH2vz/t6c/A5Pnf2fGzvrXvxvs+9Pu6effh8+PywABAgopD+Y3YDRNGOISFSYEiIFBgSIgWGhEiBISFSYEiIFBgSIgWGhEiBISFSiIvUgjdu3Ig33ngDaWlpuHDhArZs2YKurq5xvTc9PR1erzdSrREBADRNQ19f37jmCqNHWVmZGB0dFZWVlSI7O1scOHBAuN1ukZKSonxvenq6IJoq6enpyu+kBRE4wbGjowNdXV3YsmULAMBiseDKlStwOBzYu3fvP75X0zR4PB5kZGRwa0IRo2kanE4nbDab8ntm+K9b06dPR15eHmpqagI1IQRaW1tRWFiomx8fHw+r1Rp4rWkaAMDr9TIkFBUM33FPTk5GXFwcXC5XUN3lciEtLU03v6qqCh6PJzCcTqfRLRFNiulHt2pqamCz2QIjIyPD7JaIghj+69bAwADGxsZgt9uD6na7Hf39/br5fr8ffr/f6DaIDGP4luTWrVvo7u5GUVFRoGaxWFBUVIT29najP45oSkTkEPDIyIhYv369yMrKEvv37xdut1ukpqYq36tpmhBCCE3TDO+Lg+P2CPN7FpkmNm3aJHp7e8Xo6Kjo6OgQ+fn5kWieg2NCI5zvWUT+TjIZt/9OMp7j10QTFc73zPSjW0TRjiEhUmBIiBQYEiIFhoRIgSEhUmBIiBQYEiIFhoRIgSEhUmBIiBQYEiKFiN1S6N/OYrFI67IrL1taWqRzjx49qqtVVVVJ506bNk1XmzdvnnTu2rVrdbVXXnlFOjclJUValzl37pyu9tRTT0nnjoyMjHu5ZuOWhEiBISFSYEiIFBgSIgVemRghr776qrReV1c3qeXKdo4B4PHHH5/UcoeHh6V1h8Ohqw0ODkrnNjQ06Go3b96cVF+RwisTiQzEkBApMCRECgwJkQJDQqTA01IMIDslZNmyZRH5rPz8fGnd7XaPexkHDx7U1T744APp3OvXr497uXcqbkmIFBgSIgWGhEiBISFS4I67AWbPnq2rlZaWTnq5stM/9uzZI51bW1s76c8jOW5JiBQYEiIFhoRIgSEhUmBIiBR4dMsAY2Njulqoi40SExN1tVCP6JYdITt16lSY3dFkcUtCpMCQECkwJEQKDAmRAnfcDXD16lVdrampSTp33bp1utqNGzekcxMSEnS1zMxM6dwrV67oarF0K9Foxi0JkQJDQqTAkBApMCRECmGHZMmSJWhubobT6YQQAsXFxbo51dXV6Ovrw/DwMFpaWkI+J4MoFoR9dCsxMREXLlzAJ598Ij2Cs337dmzduhUVFRXo6enB7t27ceLECeTk5MDn8xnSdCz48ssvpfXVq1frajNnzpTOlT3EJxTZ6Srvv/++dK7T6dTVfv31V+nc0dHRcfdwpwo7JMePH8fx48dD/nzbtm3Ys2cPmpubAQDr16+Hy+XCmjVr8NVXX028UyKTGLpPMnfuXMyaNQutra2BmsfjQWdnJwoLC6XviY+Ph6ZpQYMomhgakrS0NACAy+UKqrtcrsDP/q6qqgoejycwZL8KEJnJ9KNbNTU1sNlsgSF78CaRmQw9LaW/vx8AYLfbA/99+/WPP/4ofY/f7w95PUUsO3bsmLQuOy3l888/l85NSkoa9+ctX758XLVQTp48Ka3v2LFDV/vhhx/Gvdw7gaFbkp6eHly7dg1FRUWBmqZpKCgoQHt7u5EfRTRlJnQI+P//7jF37lzk5ubC7XbjypUrqK2txVtvvYVffvklcAi4r68PR44cMbJvoikTdkgeffRRnD59OvB63759AIBPP/0UGzZswHvvvYfExER89NFHmDFjBtra2rBy5cp/1d9I6M4SdkjOnDkDi8Xyj3N27dqFXbt2Tbgpomhi+tEtomjHR1RHgby8PGk9NTVVVysvL5fOXbhwoa6Wk5Mzqb4A+SksslNrAIQ8ghmN+IhqIgMxJEQKDAmRAkNCpMAd9zvEPffco6s98sgj0rlPPPGErvb222+P+7O++eYbaf3555/X1aL1lCPuuBMZiCEhUmBIiBQYEiIFhoRIgUe3/oWSk5N1tVB3dwnnwq0333xTV9u7d+/4G5tCPLpFZCCGhEiBISFSYEiIFLjjTgDkp7UA8juj3HvvvdK5f7/fGgBkZWVJ53o8njC6Mx533IkMxJAQKTAkRAoMCZECQ0KkwEdUhyElJUValz2vJdRFTKEuWDLb9evXpXXZvYAPHjwonWu323W1uLjY/4pxS0KkwJAQKTAkRAoMCZFC7O9VTaFNmzZJ65mZmbra0NBQpNuZErLrTGpqaqRz77vvPl3t5Zdfls4NtYxoxC0JkQJDQqTAkBApMCRECgwJkQKPboWwdOlSXW3r1q3Sud99952u1tbWZnhPsUh2Z5ZYwy0JkQJDQqTAkBApMCRECtxxD6GkpERX8/l80rnr1q2LdDumOX36tK6WkZEx7vdfuHDBwG7MwS0JkQJDQqTAkBApMCRECmGFZOfOnTh//jw8Hg9cLheampp011JYrVbU1dVhYGAAXq8Xhw8fRmpqqqFNE02lsI5uLVu2DPX19ejq6kJcXBzeffddfPvtt8jJycHw8DAAYN++fXjmmWdQWlqKoaEh1NXV4euvv8bixYsjsgJTKSEhQVp/8cUXdbWTJ09K5166dMnQnibigQce0NWampqkc7Ozs3W1adOmSef+9NNPulpjY2OY3UWfsELy9NNPB72urKzEH3/8gby8PHz//few2Wx46aWXUF5ejlOnTgEANmzYgJ9//hkFBQXo7Ow0rnOiKTKpfZKkpCQAgNvtBgDk5eUhPj4era2tgTmXLl3C5cuXUVhYKF1GfHw8NE0LGkTRZMIhsVgsqK2tRVtbGy5evAgASEtLg8/n013f7XK5kJaWJl1OVVUVPB5PYDidzom2RBQREw5JfX09FixYgBdeeGFSDdTU1MBmswVGOH/NJZoKEzotxeFwYNWqVVi6dGnQ//n7+/thtVqRlJQUtDWx2+3o7++XLsvv98Pv90+kjSlns9mk9bq6Ol3t5s2b0rmyLeWBAwcm11gIGzZskNbvv/9+Xe3uu+8e93K/+OILaX3jxo26Wqh/h1gS9pbE4XCgpKQEK1asQG9vb9DPuru74ff7UVRUFKhlZmZizpw5aG9vn3SzRGYIa0tSX1+P8vJyFBcXw+v1Bm6QPDQ0hNHRUXg8Hnz88cf48MMP4Xa74fF44HA4cO7cOR7ZopgVVkhub07PnDkTVK+srMRnn30GAHjttdfw119/obGxEVarFSdOnJBuholiRVghsVgsyjk+nw+bN2/G5s2bJ9wUUTThuVtECnxEdQgzZszQ1WR3RQGAhQsXRrYZE8ke2BPqAUW///57pNsxDB9RTWQghoRIgSEhUmBIiBR4t5QQ/vzzT10tPz9fOnfmzJm6WjiHwEtLS6X1+fPnj3sZMocOHZLWq6urdbVQpw2NjY3pakJE1bGeiOOWhEiBISFSYEiIFBgSIgWGhEiBp6XQvxJPSyEyEENCpMCQECkwJEQKDAmRAkNCpMCQECkwJEQKDAmRAkNCpMCQECkwJEQKDAmRAkNCpMCQECkwJEQKDAmRAkNCpMCQECkwJEQKUXubU03TzG6B7mDhfL+iLiS3m5c9ypnIaJqmKe+WEnW3FAKA9PR0eL1eaJoGp9OJjIyMO+72Qlw382mahr6+PuW8qNuSANA17vV6o/ofezK4buYZb2/ccSdSYEiIFKI6JD6fD++88w58Pp/ZrRiO6xY7onLHnSiaRPWWhCgaMCRECgwJkQJDQqQQ1SHZuHEjenp6MDIygo6ODjz22GNmtxS2JUuWoLm5GU6nE0IIFBcX6+ZUV1ejr68Pw8PDaGlpwbx580zoNDw7d+7E+fPn4fF44HK50NTUhMzMzKA5VqsVdXV1GBgYgNfrxeHDh5GammpSx5MjonGUlZWJ0dFRUVlZKbKzs8WBAweE2+0WKSkppvcWzli5cqXYvXu3WLNmjRBCiOLi4qCfb9++XQwODorVq1eLhx56SBw5ckT89ttvwmq1mt77P41jx46JiooKkZOTIx5++GFx9OhR0dvbK+66667AnIaGBnH58mWxfPlysWjRInHu3DnR1tZmeu8TGKY3IB0dHR3C4XAEXlssFnH16lWxY8cO03ub6JCFpK+vT7z++uuB1zabTYyMjIi1a9ea3m84Izk5WQghxJIlSwLr4fP5xHPPPReYM3/+fCGEEAUFBab3G86Iyl+3pk+fjry8PLS2tgZqQgi0traisLDQxM6MNXfuXMyaNStoPT0eDzo7O2NuPZOSkgAAbrcbAJCXl4f4+Pigdbt06RIuX74cc+sWlSFJTk5GXFwcXC5XUN3lciEtLc2krox3e11ifT0tFgtqa2vR1taGixcvAvjfuvl8PgwNDQXNjbV1A6L0LGCKLfX19ViwYAEWL15sdisREZVbkoGBAYyNjcFutwfV7XY7+vv7TerKeLfXJZbX0+FwYNWqVVi+fHnQhXL9/f2wWq2BX8Nui6V1uy0qQ3Lr1i10d3ejqKgoULNYLCgqKkJ7e7uJnRmrp6cH165dC1pPTdNQUFAQE+vpcDhQUlKCFStWoLe3N+hn3d3d8Pv9QeuWmZmJOXPmxMS6/Z3pRw9ko6ysTIyMjIj169eLrKwssX//fuF2u0VqaqrpvYUzEhMTRW5ursjNzRVCCLFt2zaRm5srZs+eLYD/HQJ2u93i2WefFQsWLBBNTU0xcQi4vr5eDA4OiqVLlwq73R4YCQkJgTkNDQ2it7dXPPnkk2LRokXi7Nmz4uzZs6b3PoFhegMhx6ZNm0Rvb68YHR0VHR0dIj8/3/Sewh3Lli0TMocOHQrMqa6uFteuXRMjIyOipaVFPPjgg6b3rRqhVFRUBOZYrVZRV1cnrl+/Lm7cuCEaGxuF3W43vfdwB0+VJ1KIyn0SomjCkBApMCRECgwJkQJDQqTAkBApMCRECgwJkQJDQqTAkBApMCRECgwJkcJ/ARsaR2FngGHbAAAAAElFTkSuQmCC\n"},"metadata":{}}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"required_libs":[]},"nbformat":4,"nbformat_minor":5}